import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from statsmodels.tsa.statespace.sarimax import SARIMAX
from prophet import Prophet
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_absolute_error
from datetime import datetime, timedelta
from io import BytesIO
from fpdf import FPDF
import warnings
import logging
import tempfile
import os
from scipy import stats
import optuna
from pmdarima import auto_arima
import joblib

# Configura√ß√µes iniciais
warnings.filterwarnings("ignore")
logging.basicConfig(filename='demand_forecast.log', level=logging.ERROR)

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Sistema Avan√ßado de Previs√£o de Demanda ",
    page_icon="üçû",
    layout="wide",
    initial_sidebar_state="expanded"
)


class AdvancedDemandForecastSystem:
    def __init__(self):
        self.data = pd.DataFrame(columns=['Data', 'Unidades Vendidas'])
        self.forecast_results = None
        self.model_performance = {}
        self.initialize_session_state()
        self.setup_data_validation()

    def initialize_session_state(self):
        """Inicializa o estado da sess√£o para persist√™ncia de dados"""
        if 'data' not in st.session_state:
            st.session_state.data = self.data
        if 'forecast_results' not in st.session_state:
            st.session_state.forecast_results = None
        if 'model_performance' not in st.session_state:
            st.session_state.model_performance = {}
        if 'model_params' not in st.session_state:
            st.session_state.model_params = {
                'ARIMA': {'order': (5, 1, 0)},
                'SARIMA': {'order': (1, 1, 1), 'seasonal_order': (1, 1, 1, 7)},
                'Holt-Winters': {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7},
                'Random Forest': {'n_estimators': 100, 'max_depth': None},
                'XGBoost': {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1},
                'Prophet': {'changepoint_prior_scale': 0.05, 'seasonality_prior_scale': 10}
            }
        if 'data_quality_report' not in st.session_state:
            st.session_state.data_quality_report = None

    def setup_data_validation(self):
        """Configura regras de valida√ß√£o de dados"""
        self.validation_rules = {
            'negative_values': lambda df: (df['Unidades Vendidas'] < 0).sum(),
            'missing_dates': self._check_missing_dates,
            'outliers': self._detect_outliers
        }

    def _check_missing_dates(self, df):
        """Verifica datas faltantes na s√©rie temporal"""
        if len(df) < 2:
            return 0
        full_date_range = pd.date_range(start=df['Data'].min(), end=df['Data'].max())
        missing_dates = full_date_range.difference(df['Data'])
        return len(missing_dates)

    def _detect_outliers(self, df):
        """Detecta outliers usando IQR"""
        if len(df) < 10:
            return 0
        q1 = df['Unidades Vendidas'].quantile(0.25)
        q3 = df['Unidades Vendidas'].quantile(0.75)
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr
        return ((df['Unidades Vendidas'] < lower_bound) | (df['Unidades Vendidas'] > upper_bound)).sum()

    def load_data(self):
        """Carrega dados da sess√£o"""
        self.data = st.session_state.data
        self.forecast_results = st.session_state.forecast_results
        self.model_performance = st.session_state.model_performance
        self.data_quality_report = st.session_state.data_quality_report

    def save_data(self):
        """Salva dados na sess√£o"""
        st.session_state.data = self.data
        st.session_state.forecast_results = self.forecast_results
        st.session_state.model_performance = self.model_performance
        st.session_state.data_quality_report = self.data_quality_report

    def validate_data(self, df):
        """Realiza valida√ß√£o de qualidade dos dados"""
        report = {}
        for name, func in self.validation_rules.items():
            report[name] = func(df)
        return report

    def preprocess_data(self, df):
        """Preprocessa os dados antes da an√°lise"""
        # Preenche datas faltantes
        if len(df) > 1:
            full_date_range = pd.date_range(start=df['Data'].min(), end=df['Data'].max(), name='Data')
            df = df.set_index('Data').reindex(full_date_range).reset_index()
            df['Unidades Vendidas'] = df['Unidades Vendidas'].interpolate(method='linear')

        # Remove outliers usando Z-score (para s√©ries com mais de 30 pontos)
        if len(df) > 30:
            z_scores = np.abs(stats.zscore(df['Unidades Vendidas'].dropna()))
            df.loc[z_scores > 3, 'Unidades Vendidas'] = np.nan
            df['Unidades Vendidas'] = df['Unidades Vendidas'].interpolate(method='linear')

        return df.dropna().reset_index(drop=True)

    def import_data(self, uploaded_files):
        """Importa dados de um ou mais arquivos"""
        try:
            dfs = []
            for uploaded_file in uploaded_files:
                if uploaded_file.name.endswith('.xlsx'):
                    df = pd.read_excel(uploaded_file)
                else:
                    df = pd.read_csv(uploaded_file)

                # Verificar colunas necess√°rias
                if 'Data' not in df.columns or 'Unidades Vendidas' not in df.columns:
                    st.error(f"O arquivo {uploaded_file.name} deve conter colunas 'Data' e 'Unidades Vendidas'")
                    continue

                # Converter data para datetime
                df['Data'] = pd.to_datetime(df['Data'])
                dfs.append(df)

            if not dfs:
                return False

            new_data = pd.concat(dfs, ignore_index=True)

            # Ordenar por data
            new_data = new_data.sort_values('Data')

            # Verificar duplicatas
            if new_data['Data'].duplicated().any():
                st.warning("Foram encontradas datas duplicadas. Ser√£o mantidos apenas os √∫ltimos valores.")
                new_data = new_data.drop_duplicates('Data', keep='last')

            # Pr√©-processamento
            new_data = self.preprocess_data(new_data)

            # Valida√ß√£o de dados
            self.data_quality_report = self.validate_data(new_data)

            self.data = new_data
            self.save_data()

            # Backup autom√°tico
            self.create_backup()

            st.success(f"Dados importados com sucesso! {len(self.data)} registros carregados.")
            return True

        except Exception as e:
            st.error(f"Falha ao importar arquivo: {str(e)}")
            logging.error(f"Erro na importa√ß√£o de dados: {str(e)}")
            return False

    def create_backup(self):
        """Cria backup dos dados"""
        try:
            backup_dir = os.path.join(tempfile.gettempdir(), "demand_forecast_backups")
            os.makedirs(backup_dir, exist_ok=True)

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_path = os.path.join(backup_dir, f"backup_{timestamp}.csv")

            self.data.to_csv(backup_path, index=False)
        except Exception as e:
            logging.error(f"Erro ao criar backup: {str(e)}")

    def add_manual_data(self, date, units):
        """Adiciona dados inseridos manualmente"""
        try:
            date = pd.to_datetime(date)
            units = float(units)

            if units < 0:
                st.error("Valores negativos n√£o s√£o permitidos")
                return False

            # Verificar se data j√° existe
            if not self.data.empty and date in pd.to_datetime(self.data['Data']).values:
                # Remover entrada existente
                self.data = self.data[pd.to_datetime(self.data['Data']) != date]

            # Adicionar novo dado
            new_data = pd.DataFrame([[date, units]], columns=['Data', 'Unidades Vendidas'])
            self.data = pd.concat([self.data, new_data], ignore_index=True)
            self.data.sort_values('Data', inplace=True)

            # Pr√©-processamento ap√≥s adi√ß√£o
            self.data = self.preprocess_data(self.data)

            self.save_data()
            st.success("Dados adicionados com sucesso!")
            return True

        except ValueError as e:
            st.error(f"Formato inv√°lido: {str(e)}")
            return False

    def clear_data(self):
        """Limpa todos os dados"""
        self.data = pd.DataFrame(columns=['Data', 'Unidades Vendidas'])
        self.forecast_results = None
        self.model_performance = {}
        self.data_quality_report = None
        self.save_data()
        st.success("Dados limpos com sucesso!")

    def run_forecast(self, model_name, horizon, **kwargs):
        """Executa a previs√£o de demanda"""
        try:
            ts_data = self.data.set_index('Data')['Unidades Vendidas']

            if len(ts_data) < 30:
                st.warning("S√©rie temporal muito curta para previs√µes confi√°veis")
                return False

            with st.spinner(f"Treinando modelo {model_name}..."):
                progress_bar = st.progress(0)

                if model_name == "ARIMA":
                    order = st.session_state.model_params['ARIMA']['order']
                    forecast, performance = self.arima_forecast(ts_data, horizon, order)
                elif model_name == "SARIMA":
                    order = st.session_state.model_params['SARIMA']['order']
                    seasonal_order = st.session_state.model_params['SARIMA']['seasonal_order']
                    forecast, performance = self.sarima_forecast(ts_data, horizon, order, seasonal_order)
                elif model_name == "Holt-Winters":
                    params = st.session_state.model_params['Holt-Winters']
                    forecast, performance = self.holt_winters_forecast(ts_data, horizon, **params)
                elif model_name == "Random Forest":
                    params = st.session_state.model_params['Random Forest']
                    forecast, performance = self.random_forest_forecast(ts_data, horizon, **params)
                elif model_name == "XGBoost":
                    params = st.session_state.model_params['XGBoost']
                    forecast, performance = self.xgboost_forecast(ts_data, horizon, **params)
                elif model_name == "Prophet":
                    params = st.session_state.model_params['Prophet']
                    forecast, performance = self.prophet_forecast(ts_data, horizon, **params)
                else:
                    st.error("Modelo n√£o reconhecido")
                    return False

                progress_bar.progress(100)

            self.forecast_results = {
                'model': model_name,
                'horizon': horizon,
                'forecast': forecast,
                'last_date': ts_data.index[-1],
                'execution_date': datetime.now(),
                'performance': performance
            }

            # Atualiza hist√≥rico de performance
            if model_name not in self.model_performance:
                self.model_performance[model_name] = []
            self.model_performance[model_name].append({
                'date': datetime.now(),
                'horizon': horizon,
                'mae': performance['mae'],
                'rmse': performance['rmse']
            })

            self.save_data()
            st.success("Previs√£o realizada com sucesso!")
            return True

        except Exception as e:
            st.error(f"Falha na previs√£o: {str(e)}")
            logging.error(f"Erro na previs√£o com {model_name}: {str(e)}")
            return False

    def evaluate_model(self, y_true, y_pred):
        """Avalia o desempenho do modelo"""
        mae = mean_absolute_error(y_true, y_pred)
        rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))
        return {'mae': mae, 'rmse': rmse}

    def cross_validate(self, ts_data, model_func, horizon=7, n_splits=3):
        """Realiza valida√ß√£o cruzada temporal"""
        tscv = TimeSeriesSplit(n_splits=n_splits)
        metrics = []

        for train_index, test_index in tscv.split(ts_data):
            train = ts_data.iloc[train_index]
            test = ts_data.iloc[test_index]

            # Garante que estamos prevendo o mesmo horizonte
            if len(test) > horizon:
                test = test.iloc[:horizon]
            elif len(test) < horizon:
                continue

            forecast = model_func(train, horizon)
            metrics.append(self.evaluate_model(test, forecast))

        if not metrics:
            return {'mae': np.nan, 'rmse': np.nan}

        return {
            'mae': np.mean([m['mae'] for m in metrics]),
            'rmse': np.mean([m['rmse'] for m in metrics])
        }

    def arima_forecast(self, ts_data, horizon, order):
        """Previs√£o com modelo ARIMA"""

        def model_func(train, h):
            model = ARIMA(train, order=order)
            model_fit = model.fit()
            return model_fit.forecast(steps=h)

        # Cross-validation
        cv_metrics = self.cross_validate(ts_data, model_func, horizon)

        # Fit final
        model = ARIMA(ts_data, order=order)
        model_fit = model.fit()
        forecast = model_fit.forecast(steps=horizon)

        return forecast, cv_metrics

    def sarima_forecast(self, ts_data, horizon, order, seasonal_order):
        """Previs√£o com modelo SARIMA"""

        def model_func(train, h):
            model = SARIMAX(train, order=order, seasonal_order=seasonal_order)
            model_fit = model.fit(disp=False)
            return model_fit.forecast(steps=h)

        # Cross-validation
        cv_metrics = self.cross_validate(ts_data, model_func, horizon)

        # Fit final
        model = SARIMAX(ts_data, order=order, seasonal_order=seasonal_order)
        model_fit = model.fit(disp=False)
        forecast = model_fit.forecast(steps=horizon)

        return forecast, cv_metrics

    def holt_winters_forecast(self, ts_data, horizon, trend, seasonal, seasonal_periods):
        """Previs√£o com modelo Holt-Winters"""

        def model_func(train, h):
            model = ExponentialSmoothing(
                train,
                trend=trend,
                seasonal=seasonal,
                seasonal_periods=seasonal_periods
            )
            model_fit = model.fit()
            return model_fit.forecast(h)

        # Cross-validation
        cv_metrics = self.cross_validate(ts_data, model_func, horizon)

        # Fit final
        model = ExponentialSmoothing(
            ts_data,
            trend=trend,
            seasonal=seasonal,
            seasonal_periods=seasonal_periods
        )
        model_fit = model.fit()
        forecast = model_fit.forecast(horizon)

        return forecast, cv_metrics

    def random_forest_forecast(self, ts_data, horizon, n_estimators, max_depth):
        """Previs√£o com Random Forest"""

        def model_func(train, h):
            # Criar features
            df = pd.DataFrame({'y': train})
            for i in range(1, 8):
                df[f'lag_{i}'] = df['y'].shift(i)
            df = df.dropna()

            # Treinar modelo
            X = df.drop('y', axis=1)
            y = df['y']
            model = RandomForestRegressor(
                n_estimators=n_estimators,
                max_depth=max_depth,
                random_state=42,
                n_jobs=-1  # Usa todos os cores dispon√≠veis
            )
            model.fit(X, y)

            # Fazer previs√£o
            last_values = df.iloc[-1][['y'] + [f'lag_{i}' for i in range(1, 7)]].values
            forecasts = []

            for _ in range(h):
                next_pred = model.predict([last_values])[0]
                forecasts.append(next_pred)
                last_values = np.concatenate([[next_pred], last_values[:-1]])

            return pd.Series(forecasts)

        # Cross-validation
        cv_metrics = self.cross_validate(ts_data, model_func, horizon)

        # Fit final
        forecast = model_func(ts_data, horizon)

        return forecast, cv_metrics

    def xgboost_forecast(self, ts_data, horizon, n_estimators, max_depth, learning_rate):
        """Previs√£o com XGBoost"""

        def model_func(train, h):
            # Criar features
            df = pd.DataFrame({'y': train})
            for i in range(1, 8):
                df[f'lag_{i}'] = df['y'].shift(i)
            df = df.dropna()

            # Treinar modelo
            X = df.drop('y', axis=1)
            y = df['y']
            model = XGBRegressor(
                n_estimators=n_estimators,
                max_depth=max_depth,
                learning_rate=learning_rate,
                random_state=42,
                n_jobs=-1
            )
            model.fit(X, y)

            # Fazer previs√£o
            last_values = df.iloc[-1][['y'] + [f'lag_{i}' for i in range(1, 7)]].values
            forecasts = []

            for _ in range(h):
                next_pred = model.predict([last_values])[0]
                forecasts.append(next_pred)
                last_values = np.concatenate([[next_pred], last_values[:-1]])

            return pd.Series(forecasts)

        # Cross-validation
        cv_metrics = self.cross_validate(ts_data, model_func, horizon)

        # Fit final
        forecast = model_func(ts_data, horizon)

        return forecast, cv_metrics

    def prophet_forecast(self, ts_data, horizon, changepoint_prior_scale, seasonality_prior_scale):
        """Previs√£o com Facebook Prophet"""

        def model_func(train, h):
            df = train.reset_index()
            df.columns = ['ds', 'y']

            model = Prophet(
                changepoint_prior_scale=changepoint_prior_scale,
                seasonality_prior_scale=seasonality_prior_scale,
                daily_seasonality=False,
                weekly_seasonality=True,
                yearly_seasonality=False
            )
            model.fit(df)

            future = model.make_future_dataframe(periods=h)
            forecast = model.predict(future)

            return forecast.tail(h)['yhat'].values

        # Cross-validation
        cv_metrics = self.cross_validate(ts_data, model_func, horizon)

        # Fit final
        forecast_values = model_func(ts_data, horizon)
        forecast_dates = pd.date_range(
            start=ts_data.index[-1] + timedelta(days=1),
            periods=horizon
        )
        forecast = pd.Series(forecast_values, index=forecast_dates)

        return forecast, cv_metrics

    def auto_tune_arima(self):
        """Ajuste autom√°tico de hiperpar√¢metros ARIMA"""
        if self.data.empty or len(self.data) < 30:
            st.warning("S√£o necess√°rios pelo menos 30 dias de dados para o ajuste autom√°tico")
            return

        with st.spinner("Executando ajuste autom√°tico de ARIMA..."):
            ts_data = self.data.set_index('Data')['Unidades Vendidas']

            # Usando pmdarima para encontrar os melhores par√¢metros
            model = auto_arima(
                ts_data,
                start_p=1, start_q=1,
                max_p=5, max_q=5,
                d=1, max_d=2,
                seasonal=False,
                trace=False,
                error_action='ignore',
                suppress_warnings=True,
                stepwise=True
            )

            st.session_state.model_params['ARIMA']['order'] = model.order
            st.success(f"Melhores par√¢metros encontrados: ARIMA{model.order}")

    def auto_tune_sarima(self):
        """Ajuste autom√°tico de hiperpar√¢metros SARIMA"""
        if self.data.empty or len(self.data) < 90:
            st.warning("S√£o necess√°rios pelo menos 90 dias de dados para o ajuste autom√°tico SARIMA")
            return

        with st.spinner("Executando ajuste autom√°tico de SARIMA..."):
            ts_data = self.data.set_index('Data')['Unidades Vendidas']

            # Usando pmdarima para encontrar os melhores par√¢metros
            model = auto_arima(
                ts_data,
                start_p=1, start_q=1,
                max_p=2, max_q=2,
                d=1, max_d=2,
                start_P=1, start_Q=1,
                max_P=2, max_Q=2,
                D=1, max_D=2,
                m=7,  # Sazonalidade semanal
                seasonal=True,
                trace=False,
                error_action='ignore',
                suppress_warnings=True,
                stepwise=True
            )

            st.session_state.model_params['SARIMA']['order'] = model.order
            st.session_state.model_params['SARIMA']['seasonal_order'] = model.seasonal_order
            st.success(f"Melhores par√¢metros encontrados: SARIMA{model.order}{model.seasonal_order}")

    def auto_tune_prophet(self):
        """Ajuste autom√°tico de hiperpar√¢metros do Prophet"""
        if self.data.empty or len(self.data) < 60:
            st.warning("S√£o necess√°rios pelo menos 60 dias de dados para o ajuste autom√°tico do Prophet")
            return

        with st.spinner("Executando ajuste autom√°tico do Prophet..."):
            ts_data = self.data.set_index('Data')['Unidades Vendidas']
            df = ts_data.reset_index()
            df.columns = ['ds', 'y']

            def objective(trial):
                changepoint_prior_scale = trial.suggest_float('changepoint_prior_scale', 0.001, 0.5)
                seasonality_prior_scale = trial.suggest_float('seasonality_prior_scale', 0.01, 50)

                # Valida√ß√£o cruzada
                tscv = TimeSeriesSplit(n_splits=3)
                mae_scores = []

                for train_index, test_index in tscv.split(ts_data):
                    train = ts_data.iloc[train_index].reset_index()
                    train.columns = ['ds', 'y']
                    test = ts_data.iloc[test_index]

                    if len(test) < 7:
                        continue

                    test = test.iloc[:7]  # Avaliamos apenas 7 dias para consist√™ncia

                    model = Prophet(
                        changepoint_prior_scale=changepoint_prior_scale,
                        seasonality_prior_scale=seasonality_prior_scale,
                        daily_seasonality=False,
                        weekly_seasonality=True,
                        yearly_seasonality=False
                    )
                    model.fit(train)

                    future = model.make_future_dataframe(periods=7)
                    forecast = model.predict(future)

                    pred = forecast.tail(7)['yhat'].values
                    mae = mean_absolute_error(test, pred)
                    mae_scores.append(mae)

                if not mae_scores:
                    return float('inf')

                return np.mean(mae_scores)

            study = optuna.create_study(direction='minimize')
            study.optimize(objective, n_trials=20)

            best_params = study.best_params
            st.session_state.model_params['Prophet'] = best_params
            st.success(f"Melhores par√¢metros encontrados: {best_params}")

    def export_to_excel(self):
        """Exporta dados para Excel"""
        if self.data.empty:
            st.warning("Nenhum dado para exportar")
            return None

        output = BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            self.data.to_excel(writer, sheet_name='Dados Hist√≥ricos', index=False)

            if self.forecast_results:
                forecast_dates = pd.date_range(
                    start=self.forecast_results['last_date'] + timedelta(days=1),
                    periods=self.forecast_results['horizon']
                )
                forecast_df = pd.DataFrame({
                    'Data': forecast_dates,
                    'Unidades Previstas': self.forecast_results['forecast'],
                    'Modelo': self.forecast_results['model'],
                    'MAE': self.forecast_results['performance']['mae'],
                    'RMSE': self.forecast_results['performance']['rmse']
                })
                forecast_df.to_excel(writer, sheet_name='Previs√µes', index=False)

            # Adicionar m√©tricas de performance
            if self.model_performance:
                for model_name, runs in self.model_performance.items():
                    perf_df = pd.DataFrame(runs)
                    perf_df.to_excel(writer, sheet_name=f'Perf_{model_name}', index=False)

        return output

    def export_to_pdf(self):
        """Exporta relat√≥rio para PDF"""
        if not self.forecast_results:
            st.warning("Nenhuma previs√£o dispon√≠vel para exportar")
            return None

        try:
            pdf = FPDF()
            pdf.add_page()
            pdf.set_font("Arial", size=12)

            # Cabe√ßalho
            pdf.set_font("Arial", 'B', 16)
            pdf.cell(0, 10, "Relat√≥rio de Previs√£o de Demanda", 0, 1, 'C')
            pdf.ln(10)

            # Informa√ß√µes b√°sicas
            pdf.set_font("Arial", 'B', 12)
            pdf.cell(0, 10, "Informa√ß√µes Gerais:", 0, 1)
            pdf.set_font("Arial", size=10)

            pdf.cell(50, 10, "Data do relat√≥rio:", 0, 0)
            pdf.cell(0, 10, self.forecast_results['execution_date'].strftime('%d/%m/%Y %H:%M'), 0, 1)

            pdf.cell(50, 10, "Modelo usado:", 0, 0)
            pdf.cell(0, 10, self.forecast_results['model'], 0, 1)

            pdf.cell(50, 10, "Per√≠odo previsto:", 0, 0)
            pdf.cell(0, 10, f"{self.forecast_results['horizon']} dias", 0, 1)

            pdf.cell(50, 10, "MAE (Valida√ß√£o):", 0, 0)
            pdf.cell(0, 10, f"{self.forecast_results['performance']['mae']:.2f}", 0, 1)

            pdf.cell(50, 10, "RMSE (Valida√ß√£o):", 0, 0)
            pdf.cell(0, 10, f"{self.forecast_results['performance']['rmse']:.2f}", 0, 1)
            pdf.ln(10)

            # Estat√≠sticas
            pdf.set_font("Arial", 'B', 12)
            pdf.cell(0, 10, "Estat√≠sticas da Previs√£o:", 0, 1)
            pdf.set_font("Arial", size=10)

            forecast_data = self.forecast_results['forecast']
            stats = [
                ("M√©dia di√°ria:", f"{forecast_data.mean():.2f} unidades"),
                ("M√≠nimo di√°rio:", f"{forecast_data.min():.2f} unidades"),
                ("M√°ximo di√°rio:", f"{forecast_data.max():.2f} unidades"),
                ("Total previsto:", f"{forecast_data.sum():.2f} unidades")
            ]

            for label, value in stats:
                pdf.cell(50, 10, label, 0, 0)
                pdf.cell(0, 10, value, 0, 1)

            pdf.ln(10)

            # Tabela de previs√µes
            pdf.set_font("Arial", 'B', 12)
            pdf.cell(0, 10, "Previs√µes Di√°rias:", 0, 1)
            pdf.set_font("Arial", size=10)

            # Cabe√ßalho da tabela
            pdf.cell(40, 10, "Data", 1, 0, 'C')
            pdf.cell(40, 10, "Unidades Previstas", 1, 1, 'C')

            # Dados da tabela
            forecast_dates = pd.date_range(
                start=self.forecast_results['last_date'] + timedelta(days=1),
                periods=self.forecast_results['horizon']
            )

            for date, value in zip(forecast_dates, forecast_data):
                pdf.cell(40, 10, date.strftime('%d/%m/%Y'), 1, 0, 'C')
                pdf.cell(40, 10, f"{value:.2f}", 1, 1, 'C')

            output = BytesIO()
            pdf_bytes = pdf.output(dest='S').encode('latin1')
            output.write(pdf_bytes)
            return output

        except Exception as e:
            st.error(f"Falha ao gerar PDF: {str(e)}")
            logging.error(f"Erro ao gerar PDF: {str(e)}")
            return None


# Cria√ß√£o da interface
def main():
    st.title("üçû Sistema Avan√ßado de Previs√£o de Demanda - Padaria Master")

    # Inicializa o sistema
    system = AdvancedDemandForecastSystem()
    system.load_data()

    # Barra lateral
    st.sidebar.header("Menu")
    menu_options = {
        "üìä Dados": show_data_tab,
        "üîç An√°lise": show_analysis_tab,
        "üîÆ Previs√£o": show_forecast_tab,
        "üìä Visualiza√ß√£o": show_visualization_tab,
        "üìà Desempenho": show_performance_tab,
        "üì§ Exportar": show_export_tab,
        "‚öô Configura√ß√µes": show_settings_tab
    }

    selected_tab = st.sidebar.radio("Navega√ß√£o", list(menu_options.keys()))

    # Exibe a aba selecionada
    menu_options[selected_tab](system)


def show_data_tab(system):
    """Exibe a aba de gerenciamento de dados"""
    st.header("üìä Gerenciamento de Dados")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Importar Dados")
        uploaded_files = st.file_uploader(
            "Carregar arquivos (CSV ou Excel)",
            type=['csv', 'xlsx'],
            help="Os arquivos devem conter colunas 'Data' e 'Unidades Vendidas'",
            accept_multiple_files=True
        )

        if uploaded_files:
            if st.button("Importar Arquivos"):
                if system.import_data(uploaded_files):
                    st.rerun()

    with col2:
        st.subheader("Inserir Dados Manualmente")
        with st.form("manual_data_form"):
            date = st.date_input("Data", value=datetime.now())
            units = st.number_input("Unidades Vendidas", min_value=0, step=1)

            if st.form_submit_button("Adicionar Dados"):
                if system.add_manual_data(date, units):
                    st.rerun()

    st.divider()
    st.subheader("Visualiza√ß√£o dos Dados")

    if not system.data.empty:
        # Mostrar relat√≥rio de qualidade de dados
        if system.data_quality_report:
            st.subheader("Relat√≥rio de Qualidade dos Dados")

            col1, col2, col3 = st.columns(3)
            col1.metric("Valores Negativos", system.data_quality_report['negative_values'])
            col2.metric("Datas Faltantes", system.data_quality_report['missing_dates'])
            col3.metric("Outliers Detectados", system.data_quality_report['outliers'])

            if (system.data_quality_report['negative_values'] > 0 or
                    system.data_quality_report['missing_dates'] > 0 or
                    system.data_quality_report['outliers'] > 0):
                st.warning("Foram detectados problemas nos dados. O sistema fez ajustes autom√°ticos.")

        st.dataframe(system.data, use_container_width=True)

        # Mostrar estat√≠sticas b√°sicas
        st.write(f"**Total de registros:** {len(system.data)}")
        st.write(f"**Per√≠odo:** {system.data['Data'].min().date()} a {system.data['Data'].max().date()}")

        if len(system.data) < 30:
            st.warning("S√£o necess√°rios pelo menos 30 dias de dados para previs√µes confi√°veis.")

        if st.button("Limpar Todos os Dados", type="primary"):
            system.clear_data()
            st.rerun()
    else:
        st.info("Nenhum dado carregado. Importe um arquivo ou insira dados manualmente.")


def show_analysis_tab(system):
    """Exibe a aba de an√°lise explorat√≥ria"""
    st.header("üîç An√°lise Explorat√≥ria")

    if system.data.empty:
        st.warning("Nenhum dado dispon√≠vel para an√°lise")
        return

    # Filtros de data
    min_date = system.data['Data'].min()
    max_date = system.data['Data'].max()

    col1, col2 = st.columns(2)

    with col1:
        start_date = st.date_input(
            "Data Inicial",
            min_value=min_date,
            max_value=max_date,
            value=min_date,
            key="analysis_start"
        )

    with col2:
        end_date = st.date_input(
            "Data Final",
            min_value=min_date,
            max_value=max_date,
            value=max_date,
            key="analysis_end"
        )

    # Filtrar dados
    filtered_data = system.data[
        (system.data['Data'] >= pd.to_datetime(start_date)) &
        (system.data['Data'] <= pd.to_datetime(end_date))
        ]

    if filtered_data.empty:
        st.warning("Nenhum dado no per√≠odo selecionado")
        return

    # Tabs para diferentes an√°lises
    tab1, tab2, tab3 = st.tabs(["S√©rie Temporal", "An√°lise de Sazonalidade", "Distribui√ß√£o"])

    with tab1:
        fig = px.line(
            filtered_data,
            x='Data',
            y='Unidades Vendidas',
            title='S√©rie Temporal de Vendas',
            labels={'Unidades Vendidas': 'Unidades Vendidas', 'Data': 'Data'}
        )
        fig.update_xaxes(rangeslider_visible=True)
        st.plotly_chart(fig, use_container_width=True)

        # Decomposi√ß√£o sazonal
        try:
            if len(filtered_data) >= 30:
                st.subheader("Decomposi√ß√£o Sazonal")
                decomposition_fig = make_subplots(rows=4, cols=1, shared_xaxes=True)

                # Adiciona s√©rie original
                decomposition_fig.add_trace(
                    go.Scatter(x=filtered_data['Data'], y=filtered_data['Unidades Vendidas'], name='Observado'),
                    row=1, col=1
                )

                # Adiciona tend√™ncia, sazonalidade e res√≠duos (simplificado)
                rolling_mean = filtered_data['Unidades Vendidas'].rolling(window=7).mean()
                decomposition_fig.add_trace(
                    go.Scatter(x=filtered_data['Data'], y=rolling_mean, name='Tend√™ncia'),
                    row=2, col=1
                )

                # Sazonalidade (simplificada)
                filtered_data['DiaSemana'] = filtered_data['Data'].dt.dayofweek
                seasonal = filtered_data.groupby('DiaSemana')['Unidades Vendidas'].mean()
                seasonal_component = filtered_data['DiaSemana'].map(seasonal)
                decomposition_fig.add_trace(
                    go.Scatter(x=filtered_data['Data'], y=seasonal_component, name='Sazonalidade'),
                    row=3, col=1
                )

                # Res√≠duos
                residuals = filtered_data['Unidades Vendidas'] - rolling_mean - seasonal_component
                decomposition_fig.add_trace(
                    go.Scatter(x=filtered_data['Data'], y=residuals, name='Res√≠duo'),
                    row=4, col=1
                )

                decomposition_fig.update_layout(height=800, title_text="Decomposi√ß√£o Simplificada")
                st.plotly_chart(decomposition_fig, use_container_width=True)
        except Exception as e:
            st.warning(f"N√£o foi poss√≠vel realizar a decomposi√ß√£o: {str(e)}")

    with tab2:
        filtered_data['DiaSemana'] = filtered_data['Data'].dt.day_name()
        filtered_data['Mes'] = filtered_data['Data'].dt.month_name()

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("Por Dia da Semana")
            fig = px.box(
                filtered_data,
                x='DiaSemana',
                y='Unidades Vendidas',
                title='Distribui√ß√£o por Dia da Semana'
            )
            st.plotly_chart(fig, use_container_width=True)

        with col2:
            st.subheader("M√©dia por Dia da Semana")
            mean_by_day = filtered_data.groupby('DiaSemana')['Unidades Vendidas'].mean().reset_index()
            fig = px.bar(
                mean_by_day,
                x='DiaSemana',
                y='Unidades Vendidas',
                title='M√©dia de Vendas por Dia da Semana'
            )
            st.plotly_chart(fig, use_container_width=True)

        if len(filtered_data) > 60:  # S√≥ mostra an√°lise mensal se tiver dados suficientes
            st.subheader("Padr√£o Mensal")
            monthly_data = filtered_data.groupby('Mes')['Unidades Vendidas'].mean().reset_index()
            fig = px.line(
                monthly_data,
                x='Mes',
                y='Unidades Vendidas',
                title='M√©dia de Vendas por M√™s'
            )
            st.plotly_chart(fig, use_container_width=True)

    with tab3:
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("Histograma")
            fig = px.histogram(
                filtered_data,
                x='Unidades Vendidas',
                nbins=30,
                title='Distribui√ß√£o das Vendas Di√°rias'
            )
            st.plotly_chart(fig, use_container_width=True)

        with col2:
            st.subheader("QQ-Plot")
            qq_data = stats.probplot(filtered_data['Unidades Vendidas'], dist="norm")
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=qq_data[0][0],
                y=qq_data[0][1],
                mode='markers',
                name='Dados'
            ))
            fig.add_trace(go.Scatter(
                x=qq_data[0][0],
                y=qq_data[1][0] * qq_data[1][1] + qq_data[1][2],
                mode='lines',
                name='Distribui√ß√£o Normal'
            ))
            fig.update_layout(
                title='QQ-Plot (Compara√ß√£o com Distribui√ß√£o Normal)',
                xaxis_title='Quantis Te√≥ricos',
                yaxis_title='Quantis Amostrais'
            )
            st.plotly_chart(fig, use_container_width=True)


def show_forecast_tab(system):
    """Exibe a aba de previs√£o de demanda"""
    st.header("üîÆ Previs√£o de Demanda")

    if system.data.empty:
        st.warning("Carregue dados na aba 'üìä Dados' antes de executar previs√µes.")
        return

    if len(system.data) < 30:
        st.warning("Aten√ß√£o: S√£o recomendados pelo menos 30 dias de dados para previs√µes confi√°veis.")

    col1, col2 = st.columns(2)

    with col1:
        model = st.selectbox(
            "Selecione o Modelo",
            ["ARIMA", "SARIMA", "Holt-Winters", "Random Forest", "XGBoost", "Prophet"],
            help="""ARIMA: Modelo estat√≠stico para s√©ries temporais
SARIMA: ARIMA com componente sazonal
Holt-Winters: Modelo com componentes de tend√™ncia e sazonalidade
Random Forest: Modelo de ensemble baseado em √°rvores
XGBoost: Modelo gradient boosting otimizado
Prophet: Modelo do Facebook para s√©ries temporais"""
        )

    with col2:
        horizon = st.selectbox(
            "Horizonte de Previs√£o (dias)",
            [7, 14, 30],
            help="N√∫mero de dias no futuro para prever"
        )

    # Configura√ß√µes espec√≠ficas do modelo
    if model == "ARIMA":
        st.subheader("Configura√ß√µes ARIMA")

        col1, col2, col3 = st.columns([3, 1, 1])

        with col1:
            st.write("Ordem do Modelo (p, d, q)")
            p = st.slider("p (Auto-regressivo)", 0, 5, st.session_state.model_params['ARIMA']['order'][0])
            d = st.slider("d (Diferencia√ß√£o)", 0, 2, st.session_state.model_params['ARIMA']['order'][1])
            q = st.slider("q (M√©dia m√≥vel)", 0, 5, st.session_state.model_params['ARIMA']['order'][2])

        st.session_state.model_params['ARIMA']['order'] = (p, d, q)

        if st.button("Autoajustar ARIMA"):
            system.auto_tune_arima()

    elif model == "SARIMA":
        st.subheader("Configura√ß√µes SARIMA")

        col1, col2 = st.columns(2)

        with col1:
            st.write("Ordem do Modelo (p, d, q)")
            p = st.slider("p (Auto-regressivo)", 0, 2, st.session_state.model_params['SARIMA']['order'][0])
            d = st.slider("d (Diferencia√ß√£o)", 0, 2, st.session_state.model_params['SARIMA']['order'][1])
            q = st.slider("q (M√©dia m√≥vel)", 0, 2, st.session_state.model_params['SARIMA']['order'][2])

        with col2:
            st.write("Ordem Sazonal (P, D, Q, m)")
            P = st.slider("P (Sazonal AR)", 0, 2, st.session_state.model_params['SARIMA']['seasonal_order'][0])
            D = st.slider("D (Sazonal Diff)", 0, 2, st.session_state.model_params['SARIMA']['seasonal_order'][1])
            Q = st.slider("Q (Sazonal MA)", 0, 2, st.session_state.model_params['SARIMA']['seasonal_order'][2])
            m = st.slider("m (Per√≠odo)", 7, 30, st.session_state.model_params['SARIMA']['seasonal_order'][3], step=7)

        st.session_state.model_params['SARIMA']['order'] = (p, d, q)
        st.session_state.model_params['SARIMA']['seasonal_order'] = (P, D, Q, m)

        if st.button("Autoajustar SARIMA"):
            system.auto_tune_sarima()

    elif model == "Holt-Winters":
        st.subheader("Configura√ß√µes Holt-Winters")
        col1, col2 = st.columns(2)

        with col1:
            trend = st.selectbox("Tend√™ncia", ['add', 'mul'],
                                 index=0 if st.session_state.model_params['Holt-Winters']['trend'] == 'add' else 1,
                                 help="Tipo de componente de tend√™ncia")
            seasonal = st.selectbox("Sazonalidade", ['add', 'mul'],
                                    index=0 if st.session_state.model_params['Holt-Winters'][
                                                   'seasonal'] == 'add' else 1,
                                    help="Tipo de componente sazonal")
        with col2:
            seasonal_periods = st.number_input(
                "Per√≠odo Sazonal",
                min_value=2,
                value=st.session_state.model_params['Holt-Winters']['seasonal_periods'],
                help="N√∫mero de per√≠odos em um ciclo sazonal (ex: 7 para semana)"
            )

        st.session_state.model_params['Holt-Winters'] = {
            'trend': trend,
            'seasonal': seasonal,
            'seasonal_periods': seasonal_periods
        }

    elif model == "Random Forest":
        st.subheader("Configura√ß√µes Random Forest")
        col1, col2 = st.columns(2)

        with col1:
            n_estimators = st.number_input(
                "N√∫mero de √Årvores",
                min_value=10,
                max_value=500,
                value=st.session_state.model_params['Random Forest']['n_estimators']
            )
        with col2:
            max_depth = st.number_input(
                "Profundidade M√°xima",
                min_value=1,
                max_value=20,
                value=5 if st.session_state.model_params['Random Forest']['max_depth'] is None else
                st.session_state.model_params['Random Forest']['max_depth'],
                help="None para profundidade ilimitada"
            )

        st.session_state.model_params['Random Forest'] = {
            'n_estimators': n_estimators,
            'max_depth': None if max_depth == 0 else max_depth
        }

    elif model == "XGBoost":
        st.subheader("Configura√ß√µes XGBoost")
        col1, col2 = st.columns(2)

        with col1:
            n_estimators = st.number_input(
                "N√∫mero de √Årvores",
                min_value=10,
                max_value=500,
                value=st.session_state.model_params['XGBoost']['n_estimators']
            )
            learning_rate = st.number_input(
                "Taxa de Aprendizado",
                min_value=0.01,
                max_value=1.0,
                step=0.01,
                value=st.session_state.model_params['XGBoost']['learning_rate']
            )
        with col2:
            max_depth = st.number_input(
                "Profundidade M√°xima",
                min_value=1,
                max_value=20,
                value=st.session_state.model_params['XGBoost']['max_depth']
            )

        st.session_state.model_params['XGBoost'] = {
            'n_estimators': n_estimators,
            'max_depth': max_depth,
            'learning_rate': learning_rate
        }

    else:  # Prophet
        st.subheader("Configura√ß√µes Prophet")
        col1, col2 = st.columns(2)

        with col1:
            changepoint_prior_scale = st.slider(
                "Sensibilidade a Mudan√ßas",
                min_value=0.001,
                max_value=0.5,
                value=st.session_state.model_params['Prophet']['changepoint_prior_scale'],
                step=0.001,
                help="Controla a flexibilidade da tend√™ncia"
            )
        with col2:
            seasonality_prior_scale = st.slider(
                "For√ßa da Sazonalidade",
                min_value=0.01,
                max_value=50.0,
                value=st.session_state.model_params['Prophet']['seasonality_prior_scale'],
                step=0.1,
                help="Controla a for√ßa dos componentes sazonais"
            )

        st.session_state.model_params['Prophet'] = {
            'changepoint_prior_scale': changepoint_prior_scale,
            'seasonality_prior_scale': seasonality_prior_scale
        }

        if st.button("Autoajustar Prophet"):
            system.auto_tune_prophet()

    if st.button("Executar Previs√£o", type="primary"):
        if system.run_forecast(model, horizon):
            st.rerun()

    if system.forecast_results:
        st.divider()
        st.subheader("Resultados da Previs√£o")

        # Gr√°fico de previs√£o interativo
        fig = go.Figure()

        # Adiciona dados hist√≥ricos
        fig.add_trace(go.Scatter(
            x=system.data['Data'],
            y=system.data['Unidades Vendidas'],
            mode='lines',
            name='Hist√≥rico',
            line=dict(color='blue')
        ))

        # Adiciona previs√£o
        forecast_dates = pd.date_range(
            start=system.forecast_results['last_date'] + timedelta(days=1),
            periods=system.forecast_results['horizon']
        )
        fig.add_trace(go.Scatter(
            x=forecast_dates,
            y=system.forecast_results['forecast'],
            mode='lines+markers',
            name=f'Previs√£o ({system.forecast_results["model"]})',
            line=dict(color='red', dash='dash')
        ))

        # Adiciona intervalo de confian√ßa (simulado)
        if system.forecast_results['model'] in ['ARIMA', 'SARIMA', 'Holt-Winters', 'Prophet']:
            std_dev = np.std(system.data['Unidades Vendidas'])
            upper_bound = system.forecast_results['forecast'] + 1.96 * std_dev
            lower_bound = system.forecast_results['forecast'] - 1.96 * std_dev

            fig.add_trace(go.Scatter(
                x=forecast_dates,
                y=upper_bound,
                fill=None,
                mode='lines',
                line=dict(width=0),
                showlegend=False
            ))

            fig.add_trace(go.Scatter(
                x=forecast_dates,
                y=lower_bound,
                fill='tonexty',
                mode='lines',
                line=dict(width=0),
                fillcolor='rgba(255, 0, 0, 0.1)',
                name='Intervalo de Confian√ßa (95%)'
            ))

        fig.update_layout(
            title=f"Previs√£o de Demanda - {system.forecast_results['model']}",
            xaxis_title="Data",
            yaxis_title="Unidades Vendidas",
            hovermode="x unified"
        )

        st.plotly_chart(fig, use_container_width=True)

        # Tabela de previs√µes com detalhes
        forecast_df = pd.DataFrame({
            'Data': forecast_dates,
            'Unidades Previstas': system.forecast_results['forecast'],
            'Dia da Semana': forecast_dates.day_name(),
            'MAE (Valida√ß√£o)': system.forecast_results['performance']['mae'],
            'RMSE (Valida√ß√£o)': system.forecast_results['performance']['rmse']
        })

        st.dataframe(
            forecast_df.style.format({
                'Unidades Previstas': '{:.1f}',
                'MAE (Valida√ß√£o)': '{:.1f}',
                'RMSE (Valida√ß√£o)': '{:.1f}'
            }),
            use_container_width=True,
            hide_index=True
        )


def show_visualization_tab(system):
    """Exibe a aba de visualiza√ß√£o de dados"""
    st.header("üìä Visualiza√ß√£o de Dados")

    if system.data.empty:
        st.warning("Nenhum dado dispon√≠vel para visualiza√ß√£o")
        return

    # Filtros de data
    min_date = system.data['Data'].min()
    max_date = system.data['Data'].max()

    col1, col2 = st.columns(2)

    with col1:
        start_date = st.date_input(
            "Data Inicial",
            min_value=min_date,
            max_value=max_date,
            value=min_date,
            key="viz_start"
        )

    with col2:
        end_date = st.date_input(
            "Data Final",
            min_value=min_date,
            max_value=max_date,
            value=max_date,
            key="viz_end"
        )

    # Filtrar dados
    filtered_data = system.data[
        (system.data['Data'] >= pd.to_datetime(start_date)) &
        (system.data['Data'] <= pd.to_datetime(end_date))
        ]

    if filtered_data.empty:
        st.warning("Nenhum dado no per√≠odo selecionado")
        return

    # Gr√°ficos
    tab1, tab2 = st.tabs(["S√©rie Temporal", "An√°lise por Dia da Semana"])

    with tab1:
        fig = px.line(
            filtered_data,
            x='Data',
            y='Unidades Vendidas',
            title='Vendas por Data',
            labels={'Unidades Vendidas': 'Unidades Vendidas', 'Data': 'Data'}
        )
        fig.update_xaxes(rangeslider_visible=True)
        st.plotly_chart(fig, use_container_width=True)

    with tab2:
        filtered_data['DiaSemana'] = filtered_data['Data'].dt.day_name()

        fig = make_subplots(rows=1, cols=2,
                            subplot_titles=("Distribui√ß√£o por Dia da Semana", "M√©dia de Vendas por Dia"))

        # Boxplot
        fig.add_trace(
            go.Box(
                x=filtered_data['DiaSemana'],
                y=filtered_data['Unidades Vendidas'],
                name='Distribui√ß√£o'
            ),
            row=1, col=1
        )

        # M√©dia por dia
        mean_by_day = filtered_data.groupby('DiaSemana')['Unidades Vendidas'].mean().reset_index()
        fig.add_trace(
            go.Bar(
                x=mean_by_day['DiaSemana'],
                y=mean_by_day['Unidades Vendidas'],
                name='M√©dia'
            ),
            row=1, col=2
        )

        fig.update_layout(height=500, showlegend=False)
        st.plotly_chart(fig, use_container_width=True)


def show_performance_tab(system):
    """Exibe a aba de desempenho dos modelos"""
    st.header("üìà Desempenho dos Modelos")

    if not system.model_performance:
        st.warning(
            "Nenhum modelo foi executado ainda. Execute previs√µes na aba 'üîÆ Previs√£o' para ver m√©tricas de desempenho.")
        return

    # Mostrar m√©tricas de todos os modelos
    st.subheader("Compara√ß√£o de Modelos")

    # Cria dataframe com todas as execu√ß√µes
    performance_data = []
    for model_name, runs in system.model_performance.items():
        for run in runs:
            performance_data.append({
                'Modelo': model_name,
                'Data Execu√ß√£o': run['date'].strftime('%Y-%m-%d %H:%M'),
                'Horizonte': run['horizon'],
                'MAE': run['mae'],
                'RMSE': run['rmse']
            })

    if not performance_data:
        st.warning("Nenhuma m√©trica de desempenho dispon√≠vel")
        return

    perf_df = pd.DataFrame(performance_data)

    # Melhor modelo por horizonte
    st.subheader("Melhor Modelo por Horizonte")
    for horizon in [7, 14, 30]:
        horizon_df = perf_df[perf_df['Horizonte'] == horizon]
        if not horizon_df.empty:
            best_model = horizon_df.loc[horizon_df['MAE'].idxmin()]
            st.write(f"**Horizonte {horizon} dias:** {best_model['Modelo']} (MAE: {best_model['MAE']:.1f})")

    # Gr√°fico de evolu√ß√£o do MAE
    st.subheader("Evolu√ß√£o do Erro (MAE) por Modelo")
    fig = px.line(
        perf_df,
        x='Data Execu√ß√£o',
        y='MAE',
        color='Modelo',
        facet_col='Horizonte',
        title='Evolu√ß√£o do MAE por Horizonte de Previs√£o',
        labels={'MAE': 'Erro Absoluto M√©dio', 'Data Execu√ß√£o': 'Data da Execu√ß√£o'}
    )
    st.plotly_chart(fig, use_container_width=True)

    # Tabela detalhada
    st.subheader("Hist√≥rico de Execu√ß√µes")
    st.dataframe(
        perf_df.sort_values('Data Execu√ß√£o', ascending=False),
        use_container_width=True,
        hide_index=True
    )


def show_export_tab(system):
    """Exibe a aba de exporta√ß√£o de dados"""
    st.header("üì§ Exportar Dados")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Exportar para Excel")
        if st.button("Gerar Arquivo Excel"):
            excel_file = system.export_to_excel()
            if excel_file:
                st.download_button(
                    label="Baixar Excel",
                    data=excel_file,
                    file_name="previsao_demanda.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

    with col2:
        st.subheader("Exportar para PDF")
        if st.button("Gerar Relat√≥rio PDF"):
            pdf_file = system.export_to_pdf()
            if pdf_file:
                st.download_button(
                    label="Baixar PDF",
                    data=pdf_file,
                    file_name="relatorio_previsao.pdf",
                    mime="application/pdf"
                )

    # Exportar modelo treinado
    if system.forecast_results:
        st.subheader("Exportar Modelo Treinado")
        model_name = system.forecast_results['model']

        if st.button(f"Salvar Modelo {model_name}"):
            try:
                # Simula√ß√£o - em um sistema real, salvar√≠amos o modelo real
                model_data = {
                    'model_name': model_name,
                    'parameters': st.session_state.model_params[model_name],
                    'last_training_date': datetime.now(),
                    'performance': system.forecast_results['performance']
                }

                output = BytesIO()
                joblib.dump(model_data, output)

                st.download_button(
                    label=f"Baixar Modelo {model_name}",
                    data=output.getvalue(),
                    file_name=f"modelo_{model_name.lower()}.joblib",
                    mime="application/octet-stream"
                )
            except Exception as e:
                st.error(f"Falha ao exportar modelo: {str(e)}")


def show_settings_tab(system):
    """Exibe a aba de configura√ß√µes"""
    st.header("‚öô Configura√ß√µes do Sistema")

    st.subheader("Configura√ß√µes de Modelos")

    with st.expander("Configura√ß√µes ARIMA"):
        st.write("Par√¢metros atuais:", st.session_state.model_params['ARIMA'])
        if st.button("Redefinir ARIMA"):
            st.session_state.model_params['ARIMA'] = {'order': (5, 1, 0)}
            st.rerun()

    with st.expander("Configura√ß√µes SARIMA"):
        st.write("Par√¢metros atuais:", st.session_state.model_params['SARIMA'])
        if st.button("Redefinir SARIMA"):
            st.session_state.model_params['SARIMA'] = {'order': (1, 1, 1), 'seasonal_order': (1, 1, 1, 7)}
            st.rerun()

    with st.expander("Configura√ß√µes Holt-Winters"):
        st.write("Par√¢metros atuais:", st.session_state.model_params['Holt-Winters'])
        if st.button("Redefinir Holt-Winters"):
            st.session_state.model_params['Holt-Winters'] = {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}
            st.rerun()

    with st.expander("Configura√ß√µes Random Forest"):
        st.write("Par√¢metros atuais:", st.session_state.model_params['Random Forest'])
        if st.button("Redefinir Random Forest"):
            st.session_state.model_params['Random Forest'] = {'n_estimators': 100, 'max_depth': None}
            st.rerun()

    with st.expander("Configura√ß√µes XGBoost"):
        st.write("Par√¢metros atuais:", st.session_state.model_params['XGBoost'])
        if st.button("Redefinir XGBoost"):
            st.session_state.model_params['XGBoost'] = {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1}
            st.rerun()

    with st.expander("Configura√ß√µes Prophet"):
        st.write("Par√¢metros atuais:", st.session_state.model_params['Prophet'])
        if st.button("Redefinir Prophet"):
            st.session_state.model_params['Prophet'] = {'changepoint_prior_scale': 0.05, 'seasonality_prior_scale': 10}
            st.rerun()

    st.subheader("Configura√ß√µes do Sistema")
    cache_settings = st.checkbox("Usar cache para melhor performance", value=True)
    auto_backup = st.checkbox("Ativar backup autom√°tico", value=True)

    st.subheader("Sobre o Sistema")
    st.write("""
        **Sistema Avan√ßado de Previs√£o de Demanda**  
        Vers√£o 3.0  
        Desenvolvido com Streamlit, Plotly e Scikit-learn  
        ¬© 2023 - Todos os direitos reservados
    """)


if __name__ == "__main__":
    main()