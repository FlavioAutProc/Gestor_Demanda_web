import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from prophet import Prophet
from prophet.plot import plot_plotly
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error
from datetime import datetime, timedelta
from io import BytesIO
from fpdf import FPDF
import warnings
import logging
from scipy import stats
import tempfile
import os
import json
from pmdarima import auto_arima
import optuna
from functools import lru_cache
from typing import Dict, List, Optional, Tuple, Union

# Configura√ß√µes iniciais
warnings.filterwarnings("ignore")
logging.basicConfig(filename='app_errors.log', level=logging.ERROR)

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Sistema Avan√ßado de Previs√£o de Demanda - Padaria Master",
    page_icon="üçû",
    layout="wide",
    initial_sidebar_state="expanded"
)


class AdvancedDemandForecastSystem:
    def __init__(self):
        self.data = pd.DataFrame(columns=['Data', 'Unidades Vendidas', 'Produto', 'Categoria'])
        self.forecast_results = None
        self.forecast_history = []
        self.initialize_session_state()
        self.setup_cache()

    def setup_cache(self):
        """Configura fun√ß√µes com cache para melhor desempenho"""
        self.process_data = lru_cache(maxsize=32)(self._process_data)
        self.calculate_statistics = lru_cache(maxsize=32)(self._calculate_statistics)

    def initialize_session_state(self):
        """Inicializa o estado da sess√£o para persist√™ncia de dados"""
        if 'data' not in st.session_state:
            st.session_state.data = self.data
        if 'forecast_results' not in st.session_state:
            st.session_state.forecast_results = None
        if 'forecast_history' not in st.session_state:
            st.session_state.forecast_history = []
        if 'model_params' not in st.session_state:
            st.session_state.model_params = {
                'ARIMA': {'order': (5, 1, 0)},
                'SARIMA': {'order': (1, 1, 1), 'seasonal_order': (1, 1, 1, 7)},
                'Holt-Winters': {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7},
                'Random Forest': {'n_estimators': 100, 'max_depth': None},
                'XGBoost': {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1},
                'Prophet': {'changepoint_prior_scale': 0.05, 'seasonality_prior_scale': 10}
            }
        if 'data_backups' not in st.session_state:
            st.session_state.data_backups = []

    def load_data(self):
        """Carrega dados da sess√£o"""
        self.data = st.session_state.data
        self.forecast_results = st.session_state.forecast_results
        self.forecast_history = st.session_state.forecast_history

    def save_data(self):
        """Salva dados na sess√£o e cria backup"""
        st.session_state.data = self.data
        st.session_state.forecast_results = self.forecast_results
        st.session_state.forecast_history = self.forecast_history

        # Criar backup (mant√©m √∫ltimos 5)
        if len(st.session_state.data_backups) >= 5:
            st.session_state.data_backups.pop(0)
        st.session_state.data_backups.append({
            'data': self.data.copy(),
            'forecast_results': self.forecast_results.copy() if self.forecast_results else None,
            'forecast_history': self.forecast_history.copy()
        })

    def _process_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """Processamento de dados com cache"""
        processed = data.copy()
        processed['Data'] = pd.to_datetime(processed['Data'])
        processed = processed.sort_values('Data')

        # Garantir que todas as colunas necess√°rias existam
        if 'Categoria' not in processed.columns:
            processed['Categoria'] = 'Geral'

        return processed

    def import_data(self, uploaded_files):
        """Importa dados de m√∫ltiplos arquivos com tratamento robusto de formatos"""
        try:
            new_dfs = []

            for uploaded_file in uploaded_files:
                # Leitura do arquivo
                if uploaded_file.name.endswith('.xlsx'):
                    new_data = pd.read_excel(uploaded_file)
                else:
                    # Para CSV, detecta automaticamente separador e encoding
                    new_data = pd.read_csv(uploaded_file, sep=None, engine='python', encoding='utf-8')

                # Verifica√ß√£o das colunas obrigat√≥rias
                required_cols = ['Data', 'Unidades Vendidas']
                if not all(col in new_data.columns for col in required_cols):
                    raise ValueError(f"Arquivo {uploaded_file.name} deve conter colunas 'Data' e 'Unidades Vendidas'")

                # Tratamento de datas - m√∫ltiplos formatos suportados
                new_data['Data'] = pd.to_datetime(
                    new_data['Data'],
                    dayfirst=True,  # Prioriza formato DD/MM/YYYY
                    yearfirst=False,  # S√≥ considera YYYY primeiro se dayfirst falhar
                    format='mixed',  # Aceita m√∫ltiplos formatos
                    errors='coerce'  # Converte falhas para NaT
                )

                # Remove linhas com datas inv√°lidas
                if new_data['Data'].isna().any():
                    invalid_dates = new_data[new_data['Data'].isna()]
                    st.warning(
                        f"Removidas {len(invalid_dates)} linhas com datas inv√°lidas no arquivo {uploaded_file.name}")
                    new_data = new_data.dropna(subset=['Data'])

                # Tratamento de valores num√©ricos (suporte a v√≠rgula decimal)
                if new_data['Unidades Vendidas'].dtype == object:
                    new_data['Unidades Vendidas'] = (
                        new_data['Unidades Vendidas']
                        .astype(str)
                        .str.replace(',', '.')
                        .astype(float)
                    )

                # Preenchimento de colunas opcionais
                if 'Produto' not in new_data.columns:
                    new_data['Produto'] = 'Padaria Geral'
                if 'Categoria' not in new_data.columns:
                    new_data['Categoria'] = 'Geral'

                new_dfs.append(new_data)

            if not new_dfs:
                return False

            # Consolida todos os dataframes
            new_data = pd.concat(new_dfs, ignore_index=True)

            # Processamento adicional
            new_data = self._process_data(new_data)
            new_data = self.handle_missing_dates(new_data)
            new_data = self.detect_outliers(new_data)

            # Verifica√ß√£o de duplicatas
            dup_cols = ['Data', 'Produto'] if 'Produto' in new_data.columns else ['Data']
            if new_data.duplicated(subset=dup_cols).any():
                st.warning(f"Removidas {new_data.duplicated(subset=dup_cols).sum()} duplicatas")
                new_data = new_data.drop_duplicates(subset=dup_cols, keep='last')

            # Atualiza os dados do sistema
            self.data = new_data
            self.save_data()
            st.success(f"Dados importados com sucesso! {len(self.data)} registros carregados.")
            return True

        except Exception as e:
            st.error(f"Falha na importa√ß√£o: {str(e)}")
            logging.error(f"Import error: {str(e)}")
            return False

    def handle_missing_dates(self, data: pd.DataFrame) -> pd.DataFrame:
        """Preenche datas faltantes com interpola√ß√£o"""
        if data.empty:
            return data

        # Criar range completo de datas
        date_range = pd.date_range(
            start=data['Data'].min(),
            end=data['Data'].max(),
            freq='D'
        )

        # Para cada combina√ß√£o de produto e categoria, preencher datas faltantes
        group_cols = []
        if 'Produto' in data.columns:
            group_cols.append('Produto')
        if 'Categoria' in data.columns:
            group_cols.append('Categoria')

        if not group_cols:
            # Sem agrupamento por produto/categoria
            data = data.set_index('Data').reindex(date_range)
            data['Unidades Vendidas'] = data['Unidades Vendidas'].interpolate(
                method='linear',
                limit_direction='both'
            ).fillna(0)
            return data.reset_index().rename(columns={'index': 'Data'})
        else:
            # Com agrupamento
            filled_dfs = []
            groups = data.groupby(group_cols)

            for (group_key), group_data in groups:
                if isinstance(group_key, str):
                    group_key = [group_key]

                # Reindexar para todas as datas
                group_data = group_data.set_index('Data').reindex(date_range)

                # Manter os valores de grupo
                for col, val in zip(group_cols, group_key):
                    group_data[col] = val

                # Interpolar valores faltantes
                group_data['Unidades Vendidas'] = group_data['Unidades Vendidas'].interpolate(
                    method='linear',
                    limit_direction='both'
                ).fillna(0)  # Preencher com 0 se n√£o puder interpolar

                filled_dfs.append(group_data.reset_index().rename(columns={'index': 'Data'}))

            return pd.concat(filled_dfs, ignore_index=True)

    def detect_outliers(self, data: pd.DataFrame, threshold: float = 3) -> pd.DataFrame:
        """Detecta e trata outliers usando Z-Score"""
        if data.empty:
            return data

        data = data.copy()

        # Tratar outliers por grupo (produto/categoria) se existirem
        group_cols = []
        if 'Produto' in data.columns and len(data['Produto'].unique()) > 1:
            group_cols.append('Produto')
        if 'Categoria' in data.columns and len(data['Categoria'].unique()) > 1:
            group_cols.append('Categoria')

        if not group_cols:
            # Sem agrupamento
            z_scores = np.abs(stats.zscore(data['Unidades Vendidas']))
            outliers = z_scores > threshold

            if outliers.any():
                st.warning(f"Detectados {outliers.sum()} outliers. Eles ser√£o substitu√≠dos pela mediana.")
                median_val = data['Unidades Vendidas'].median()
                data.loc[outliers, 'Unidades Vendidas'] = median_val
        else:
            # Com agrupamento
            groups = data.groupby(group_cols)
            processed_groups = []

            for _, group_data in groups:
                z_scores = np.abs(stats.zscore(group_data['Unidades Vendidas']))
                outliers = z_scores > threshold

                if outliers.any():
                    median_val = group_data['Unidades Vendidas'].median()
                    group_data.loc[outliers, 'Unidades Vendidas'] = median_val

                processed_groups.append(group_data)

            data = pd.concat(processed_groups, ignore_index=True)

        return data

    def add_manual_data(self, date: str, units: float, product: str, category: str) -> bool:
        """Adiciona dados inseridos manualmente"""
        try:
            date = pd.to_datetime(date)
            units = float(units)

            # Verificar se data j√° existe para o produto
            mask = (pd.to_datetime(self.data['Data']) == date)
            if 'Produto' in self.data.columns:
                mask &= (self.data['Produto'] == product)

            if not self.data.empty and mask.any():
                # Atualizar entrada existente
                self.data.loc[mask, 'Unidades Vendidas'] = units
            else:
                # Adicionar novo dado
                new_data = pd.DataFrame([[date, units, product, category]],
                                        columns=['Data', 'Unidades Vendidas', 'Produto', 'Categoria'])
                self.data = pd.concat([self.data, new_data], ignore_index=True)

            self.data = self._process_data(self.data)
            self.save_data()
            st.success("Dados adicionados com sucesso!")
            return True

        except ValueError as e:
            st.error(f"Formato inv√°lido: {str(e)}")
            logging.error(f"Manual data error: {str(e)}")
            return False

    def clear_data(self) -> None:
        """Limpa todos os dados"""
        self.data = pd.DataFrame(columns=['Data', 'Unidades Vendidas', 'Produto', 'Categoria'])
        self.forecast_results = None
        self.forecast_history = []
        self.save_data()
        st.success("Dados limpos com sucesso!")

    def run_forecast(self, model_name: str, horizon: int, product: Optional[str] = None,
                     category: Optional[str] = None, **kwargs) -> bool:
        """Executa a previs√£o de demanda com valida√ß√£o cruzada"""
        try:
            # Filtrar por produto e categoria se especificado
            filter_condition = True
            if product and 'Produto' in self.data.columns:
                filter_condition &= (self.data['Produto'] == product)
            if category and 'Categoria' in self.data.columns:
                filter_condition &= (self.data['Categoria'] == category)

            filtered_data = self.data[filter_condition]

            if filtered_data.empty:
                st.error("Nenhum dado encontrado para os filtros aplicados")
                return False

            ts_data = filtered_data.set_index('Data')['Unidades Vendidas']

            if len(ts_data) < 30:
                st.warning("Dados insuficientes para previs√£o confi√°vel. Recomendado pelo menos 30 pontos.")

            # Configurar progresso
            progress_bar = st.progress(0)
            status_text = st.empty()

            if model_name == "ARIMA":
                status_text.text("Ajustando modelo ARIMA...")
                order = st.session_state.model_params['ARIMA']['order']
                forecast, forecast_min, forecast_max = self.arima_forecast(ts_data, horizon, order)
                progress_bar.progress(100)

            elif model_name == "SARIMA":
                status_text.text("Ajustando modelo SARIMA...")
                order = st.session_state.model_params['SARIMA']['order']
                seasonal_order = st.session_state.model_params['SARIMA']['seasonal_order']
                forecast, forecast_min, forecast_max = self.sarima_forecast(ts_data, horizon, order, seasonal_order)
                progress_bar.progress(100)

            elif model_name == "Holt-Winters":
                status_text.text("Ajustando modelo Holt-Winters...")
                params = st.session_state.model_params['Holt-Winters']
                forecast, forecast_min, forecast_max = self.holt_winters_forecast(ts_data, horizon, **params)
                progress_bar.progress(100)

            elif model_name == "Prophet":
                status_text.text("Ajustando modelo Prophet...")
                params = st.session_state.model_params['Prophet']
                forecast, forecast_min, forecast_max = self.prophet_forecast(ts_data, horizon, **params)
                progress_bar.progress(100)

            elif model_name == "Random Forest":
                status_text.text("Treinando Random Forest com valida√ß√£o cruzada...")
                params = st.session_state.model_params['Random Forest']
                forecast, forecast_min, forecast_max = self.ml_forecast(ts_data, horizon, model='rf', **params)
                progress_bar.progress(100)

            elif model_name == "XGBoost":
                status_text.text("Treinando XGBoost com valida√ß√£o cruzada...")
                params = st.session_state.model_params['XGBoost']
                forecast, forecast_min, forecast_max = self.ml_forecast(ts_data, horizon, model='xgb', **params)
                progress_bar.progress(100)

            else:
                raise ValueError(f"Modelo desconhecido: {model_name}")

            # Calcular m√©tricas de erro se houver dados suficientes
            error_metrics = {}
            if len(ts_data) > horizon:
                train_data = ts_data.iloc[:-horizon]
                test_data = ts_data.iloc[-horizon:]

                # Re-treinar o modelo com dados de treino
                if model_name == "ARIMA":
                    model = ARIMA(train_data, order=order)
                    model_fit = model.fit()
                    test_forecast = model_fit.forecast(steps=horizon)
                elif model_name == "SARIMA":
                    model = SARIMAX(train_data, order=order, seasonal_order=seasonal_order)
                    model_fit = model.fit(disp=False)
                    test_forecast = model_fit.forecast(steps=horizon)
                elif model_name == "Holt-Winters":
                    model = ExponentialSmoothing(
                        train_data,
                        trend=params.get('trend', 'add'),
                        seasonal=params.get('seasonal', 'add'),
                        seasonal_periods=params.get('seasonal_periods', 7)
                    )
                    model_fit = model.fit()
                    test_forecast = model_fit.forecast(horizon)
                elif model_name == "Prophet":
                    df = pd.DataFrame({
                        'ds': train_data.index,
                        'y': train_data.values
                    })
                    model = Prophet(**params)
                    model.fit(df)
                    future = model.make_future_dataframe(periods=horizon)
                    test_forecast = model.predict(future).tail(horizon)['yhat'].values
                elif model_name in ["Random Forest", "XGBoost"]:
                    test_forecast, _, _ = self.ml_forecast(train_data, horizon,
                                                           model='rf' if model_name == "Random Forest" else 'xgb',
                                                           **params)

                # Calcular m√©tricas
                error_metrics = {
                    'MAPE': mean_absolute_percentage_error(test_data, test_forecast) * 100,
                    'RMSE': np.sqrt(mean_squared_error(test_data, test_forecast)),
                    'Accuracy': max(0, 100 - mean_absolute_percentage_error(test_data, test_forecast) * 100)
                }

            # Salvar resultados
            forecast_dates = pd.date_range(
                start=ts_data.index[-1] + timedelta(days=1),
                periods=horizon
            )

            forecast_df = pd.DataFrame({
                'Data': forecast_dates,
                'Unidades Previstas': forecast,
                'Previs√£o M√≠nima': forecast_min if forecast_min is not None else forecast,
                'Previs√£o M√°xima': forecast_max if forecast_max is not None else forecast,
                'Modelo': model_name,
                'Produto': product if product else 'Geral',
                'Categoria': category if category else 'Geral'
            })

            self.forecast_results = {
                'model': model_name,
                'horizon': horizon,
                'forecast': forecast_df,
                'last_date': ts_data.index[-1],
                'execution_date': datetime.now(),
                'product': product,
                'category': category,
                'error_metrics': error_metrics if error_metrics else None
            }

            # Adicionar ao hist√≥rico (mant√©m √∫ltimos 10)
            if len(self.forecast_history) >= 10:
                self.forecast_history.pop(0)
            self.forecast_history.append(self.forecast_results.copy())

            self.save_data()
            status_text.text("Previs√£o conclu√≠da com sucesso!")
            st.success("Previs√£o realizada com sucesso!")
            return True

        except Exception as e:
            st.error(f"Falha na previs√£o: {str(e)}")
            logging.error(f"Forecast error: {str(e)}")
            return False

    def arima_forecast(self, ts_data: pd.Series, horizon: int, order: Tuple[int, int, int]) -> Tuple[
        np.ndarray, Optional[np.ndarray], Optional[np.ndarray]]:
        """Previs√£o com modelo ARIMA"""
        model = ARIMA(ts_data, order=order)
        model_fit = model.fit()
        forecast = model_fit.forecast(steps=horizon)

        # Obter intervalos de confian√ßa
        conf_int = model_fit.get_forecast(steps=horizon).conf_int()
        forecast_min = conf_int.iloc[:, 0].values
        forecast_max = conf_int.iloc[:, 1].values

        return forecast.values, forecast_min, forecast_max

    def sarima_forecast(self, ts_data: pd.Series, horizon: int, order: Tuple[int, int, int],
                        seasonal_order: Tuple[int, int, int, int]) -> Tuple[
        np.ndarray, Optional[np.ndarray], Optional[np.ndarray]]:
        """Previs√£o com modelo SARIMA"""
        model = SARIMAX(ts_data, order=order, seasonal_order=seasonal_order)
        model_fit = model.fit(disp=False)
        forecast = model_fit.forecast(steps=horizon)

        # Obter intervalos de confian√ßa
        conf_int = model_fit.get_forecast(steps=horizon).conf_int()
        forecast_min = conf_int.iloc[:, 0].values
        forecast_max = conf_int.iloc[:, 1].values

        return forecast.values, forecast_min, forecast_max

    def holt_winters_forecast(self, ts_data: pd.Series, horizon: int, trend: str, seasonal: str,
                              seasonal_periods: int) -> Tuple[np.ndarray, Optional[np.ndarray], Optional[np.ndarray]]:
        """Previs√£o com modelo Holt-Winters"""
        model = ExponentialSmoothing(
            ts_data,
            trend=trend,
            seasonal=seasonal,
            seasonal_periods=seasonal_periods
        )
        model_fit = model.fit()
        forecast = model_fit.forecast(horizon)

        # Holt-Winters n√£o fornece intervalos de confian√ßa diretamente
        return forecast.values, None, None

    def prophet_forecast(self, ts_data: pd.Series, horizon: int, **params) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """Previs√£o com Facebook Prophet"""
        df = pd.DataFrame({
            'ds': ts_data.index,
            'y': ts_data.values
        })

        model = Prophet(**params, interval_width=0.95)  # 95% de intervalo de confian√ßa
        model.fit(df)

        future = model.make_future_dataframe(periods=horizon)
        forecast_df = model.predict(future).tail(horizon)

        return (
            forecast_df['yhat'].values,
            forecast_df['yhat_lower'].values,
            forecast_df['yhat_upper'].values
        )

    def ml_forecast(self, ts_data: pd.Series, horizon: int, model: str = 'rf',
                    **params) -> Tuple[np.ndarray, Optional[np.ndarray], Optional[np.ndarray]]:
        """Previs√£o com modelos de machine learning (RF ou XGBoost)"""
        # Criar features
        df = pd.DataFrame({'y': ts_data})
        for i in range(1, 8):
            df[f'lag_{i}'] = df['y'].shift(i)
        df = df.dropna()

        # Valida√ß√£o cruzada temporal
        tscv = TimeSeriesSplit(n_splits=3)
        X = df.drop('y', axis=1)
        y = df['y']

        if model == 'rf':
            model_inst = RandomForestRegressor(**params, random_state=42)
        else:
            model_inst = XGBRegressor(**params, random_state=42)

        # Treinar modelo
        model_inst.fit(X, y)

        # Fazer previs√£o
        last_values = df.iloc[-1][['y'] + [f'lag_{i}' for i in range(1, 7)]].values
        forecasts = []

        for _ in range(horizon):
            next_pred = model_inst.predict([last_values])[0]
            forecasts.append(next_pred)
            last_values = np.concatenate([[next_pred], last_values[:-1]])

        # ML models n√£o fornecem intervalos de confian√ßa diretamente
        return (
            np.array(forecasts),
            None,
            None
        )

    def auto_tune_model(self, model_name: str) -> None:
        """Otimiza√ß√£o autom√°tica de hiperpar√¢metros com Optuna"""
        try:
            if self.data.empty:
                st.warning("Nenhum dado dispon√≠vel para otimiza√ß√£o")
                return

            ts_data = self.data.set_index('Data')['Unidades Vendidas']

            if model_name == "ARIMA":
                st.info("Executando auto_arima para encontrar melhores par√¢metros...")
                model = auto_arima(
                    ts_data,
                    seasonal=False,
                    trace=True,
                    error_action='ignore',
                    suppress_warnings=True
                )
                best_order = model.order
                st.session_state.model_params['ARIMA']['order'] = best_order
                st.success(f"Melhores par√¢metros ARIMA encontrados: {best_order}")

            elif model_name == "SARIMA":
                st.info("Executando auto_arima para encontrar melhores par√¢metros SARIMA...")
                model = auto_arima(
                    ts_data,
                    seasonal=True,
                    m=7,  # Sazonalidade semanal
                    trace=True,
                    error_action='ignore',
                    suppress_warnings=True
                )
                best_order = model.order
                best_seasonal_order = model.seasonal_order
                st.session_state.model_params['SARIMA']['order'] = best_order
                st.session_state.model_params['SARIMA']['seasonal_order'] = best_seasonal_order
                st.success(f"Melhores par√¢metros SARIMA encontrados: ordem {best_order}, sazonal {best_seasonal_order}")

            elif model_name in ["Random Forest", "XGBoost"]:
                st.info(f"Otimizando {model_name} com Optuna...")

                # Preparar dados
                df = pd.DataFrame({'y': ts_data})
                for i in range(1, 8):
                    df[f'lag_{i}'] = df['y'].shift(i)
                df = df.dropna()
                X = df.drop('y', axis=1)
                y = df['y']

                def objective(trial):
                    if model_name == "Random Forest":
                        params = {
                            'n_estimators': trial.suggest_int('n_estimators', 50, 200),
                            'max_depth': trial.suggest_int('max_depth', 3, 15),
                            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10)
                        }
                        model = RandomForestRegressor(**params, random_state=42)
                    else:
                        params = {
                            'n_estimators': trial.suggest_int('n_estimators', 50, 200),
                            'max_depth': trial.suggest_int('max_depth', 3, 10),
                            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
                            'subsample': trial.suggest_float('subsample', 0.5, 1.0)
                        }
                        model = XGBRegressor(**params, random_state=42)

                    # Valida√ß√£o cruzada
                    tscv = TimeSeriesSplit(n_splits=3)
                    scores = []

                    for train_idx, test_idx in tscv.split(X):
                        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
                        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

                        model.fit(X_train, y_train)
                        score = model.score(X_test, y_test)
                        scores.append(score)

                    return np.mean(scores)

                study = optuna.create_study(direction='maximize')
                study.optimize(objective, n_trials=20)

                if model_name == "Random Forest":
                    st.session_state.model_params['Random Forest'].update({
                        'n_estimators': study.best_params['n_estimators'],
                        'max_depth': study.best_params['max_depth']
                    })
                else:
                    st.session_state.model_params['XGBoost'].update({
                        'n_estimators': study.best_params['n_estimators'],
                        'max_depth': study.best_params['max_depth'],
                        'learning_rate': study.best_params['learning_rate']
                    })

                st.success(f"Melhores par√¢metros {model_name} encontrados: {study.best_params}")

        except Exception as e:
            st.error(f"Falha na otimiza√ß√£o: {str(e)}")
            logging.error(f"Auto-tune error: {str(e)}")

    def _calculate_statistics(self, data: pd.DataFrame) -> Dict:
        """Calcula estat√≠sticas com cache"""
        if data.empty:
            return {
                'total': 0,
                'start_date': None,
                'end_date': None,
                'mean': 0,
                'median': 0,
                'std': 0,
                'min': 0,
                'max': 0
            }

        # Garantir que as colunas necess√°rias existam
        if 'Unidades Vendidas' not in data.columns:
            data['Unidades Vendidas'] = 0

        stats = {
            'total': len(data),
            'start_date': data['Data'].min(),
            'end_date': data['Data'].max(),
            'mean': data['Unidades Vendidas'].mean(),
            'median': data['Unidades Vendidas'].median(),
            'std': data['Unidades Vendidas'].std(),
            'min': data['Unidades Vendidas'].min(),
            'max': data['Unidades Vendidas'].max()
        }

        if 'Produto' in data.columns:
            stats['products'] = data['Produto'].nunique()
        if 'Categoria' in data.columns:
            stats['categories'] = data['Categoria'].nunique()

        return stats
    def export_to_excel(self) -> Optional[BytesIO]:
        """Exporta dados para Excel com todas as informa√ß√µes"""
        if self.data.empty:
            st.warning("Nenhum dado para exportar")
            return None

        output = BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            # Dados hist√≥ricos
            self.data.to_excel(writer, sheet_name='Dados Hist√≥ricos', index=False)

            # Previs√µes atuais
            if self.forecast_results:
                forecast_df = self.forecast_results['forecast']
                forecast_df.to_excel(writer, sheet_name='Previs√µes Atuais', index=False)

                # Adicionar m√©tricas de erro se existirem
                if self.forecast_results.get('error_metrics'):
                    metrics_df = pd.DataFrame.from_dict(
                        self.forecast_results['error_metrics'],
                        orient='index',
                        columns=['Valor']
                    )
                    metrics_df.to_excel(writer, sheet_name='M√©tricas de Erro')

            # Hist√≥rico de previs√µes
            if self.forecast_history:
                history_data = []
                for i, forecast in enumerate(self.forecast_history, 1):
                    forecast_df = forecast['forecast'].copy()
                    forecast_df['Execu√ß√£o'] = forecast['execution_date'].strftime('%Y-%m-%d %H:%M')
                    forecast_df['Modelo'] = forecast['model']
                    history_data.append(forecast_df)

                pd.concat(history_data).to_excel(writer, sheet_name='Hist√≥rico Previs√µes', index=False)

        return output

    def export_to_pdf(self) -> Optional[BytesIO]:
        """Exporta relat√≥rio para PDF com gr√°ficos e todas as informa√ß√µes"""
        if not self.forecast_results:
            st.warning("Nenhuma previs√£o dispon√≠vel para exportar")
            return None

        try:
            pdf = FPDF()
            pdf.add_page()
            pdf.set_font("Arial", size=12)

            # Cabe√ßalho
            pdf.set_font("Arial", 'B', 16)
            pdf.cell(0, 10, "Relat√≥rio de Previs√£o de Demanda", 0, 1, 'C')
            pdf.ln(10)

            # Informa√ß√µes b√°sicas
            pdf.set_font("Arial", 'B', 12)
            pdf.cell(0, 10, "Informa√ß√µes Gerais:", 0, 1)
            pdf.set_font("Arial", size=10)

            pdf.cell(50, 10, "Data do relat√≥rio:", 0, 0)
            pdf.cell(0, 10, self.forecast_results['execution_date'].strftime('%d/%m/%Y %H:%M'), 0, 1)

            pdf.cell(50, 10, "Modelo usado:", 0, 0)
            pdf.cell(0, 10, self.forecast_results['model'], 0, 1)

            pdf.cell(50, 10, "Per√≠odo previsto:", 0, 0)
            pdf.cell(0, 10, f"{self.forecast_results['horizon']} dias", 0, 1)

            if self.forecast_results.get('product'):
                pdf.cell(50, 10, "Produto:", 0, 0)
                pdf.cell(0, 10, self.forecast_results['product'], 0, 1)

            if self.forecast_results.get('category'):
                pdf.cell(50, 10, "Categoria:", 0, 0)
                pdf.cell(0, 10, self.forecast_results['category'], 0, 1)

            pdf.ln(10)

            # Estat√≠sticas
            pdf.set_font("Arial", 'B', 12)
            pdf.cell(0, 10, "Estat√≠sticas da Previs√£o:", 0, 1)
            pdf.set_font("Arial", size=10)

            forecast_data = self.forecast_results['forecast']['Unidades Previstas']
            stats = [
                ("M√©dia di√°ria:", f"{forecast_data.mean():.2f} unidades"),
                ("M√≠nimo di√°rio:", f"{forecast_data.min():.2f} unidades"),
                ("M√°ximo di√°rio:", f"{forecast_data.max():.2f} unidades"),
                ("Total previsto:", f"{forecast_data.sum():.2f} unidades")
            ]

            # Adicionar m√©tricas de erro se existirem
            if self.forecast_results.get('error_metrics'):
                stats.extend([
                    ("MAPE (Erro %):", f"{self.forecast_results['error_metrics']['MAPE']:.2f}%"),
                    ("RMSE:", f"{self.forecast_results['error_metrics']['RMSE']:.2f}"),
                    ("Taxa de Acerto:", f"{self.forecast_results['error_metrics']['Accuracy']:.2f}%")
                ])

            for label, value in stats:
                pdf.cell(50, 10, label, 0, 0)
                pdf.cell(0, 10, value, 0, 1)

            pdf.ln(10)

            # Tabela de previs√µes
            pdf.set_font("Arial", 'B', 12)
            pdf.cell(0, 10, "Previs√µes Di√°rias:", 0, 1)
            pdf.set_font("Arial", size=10)

            # Cabe√ßalho da tabela
            pdf.cell(40, 10, "Data", 1, 0, 'C')
            pdf.cell(30, 10, "Dia Semana", 1, 0, 'C')
            pdf.cell(40, 10, "Unidades Previstas", 1, 0, 'C')
            pdf.cell(40, 10, "Previs√£o M√≠nima", 1, 0, 'C')
            pdf.cell(40, 10, "Previs√£o M√°xima", 1, 1, 'C')

            # Dados da tabela
            for _, row in self.forecast_results['forecast'].iterrows():
                pdf.cell(40, 10, row['Data'].strftime('%d/%m/%Y'), 1, 0, 'C')
                pdf.cell(30, 10, row['Data'].strftime('%A'), 1, 0, 'C')
                pdf.cell(40, 10, f"{row['Unidades Previstas']:.2f}", 1, 0, 'C')
                pdf.cell(40, 10, f"{row['Previs√£o M√≠nima']:.2f}", 1, 0, 'C')
                pdf.cell(40, 10, f"{row['Previs√£o M√°xima']:.2f}", 1, 1, 'C')

            # Adicionar gr√°fico (simplificado - em produ√ß√£o, salvaria uma imagem)
            pdf.ln(10)
            pdf.set_font("Arial", 'B', 12)
            pdf.cell(0, 10, "Gr√°fico de Previs√£o:", 0, 1)
            pdf.cell(0, 10, "[Gr√°fico seria exibido aqui na vers√£o completa]", 0, 1)

            output = BytesIO()
            pdf_bytes = pdf.output(dest='S').encode('latin1')
            output.write(pdf_bytes)
            return output

        except Exception as e:
            st.error(f"Falha ao gerar PDF: {str(e)}")
            logging.error(f"PDF export error: {str(e)}")
            return None

    def get_product_list(self) -> List[str]:
        """Retorna lista de produtos √∫nicos"""
        if 'Produto' not in self.data.columns:
            return []
        return sorted(self.data['Produto'].unique().tolist())

    def get_category_list(self) -> List[str]:
        """Retorna lista de categorias √∫nicas"""
        if 'Categoria' not in self.data.columns:
            return []
        return sorted(self.data['Categoria'].unique().tolist())


# Cria√ß√£o da interface aprimorada
def main():
    st.title("üçû Sistema Avan√ßado de Previs√£o de Demanda - Padaria Master")

    # Inicializa o sistema
    system = AdvancedDemandForecastSystem()
    system.load_data()

    # Barra lateral
    st.sidebar.header("Menu")
    menu_options = {
        "üìä Dados": show_data_tab,
        "üîÆ Previs√£o": show_forecast_tab,
        "üìä Visualiza√ß√£o": show_visualization_tab,
        "üìà Estat√≠sticas": show_stats_tab,
        "üì§ Exportar": show_export_tab,
        "‚öô Configura√ß√µes": show_settings_tab
    }

    selected_tab = st.sidebar.radio("Navega√ß√£o", list(menu_options.keys()))

    # Exibe a aba selecionada
    menu_options[selected_tab](system)


def show_data_tab(system: AdvancedDemandForecastSystem) -> None:
    """Exibe a aba de gerenciamento de dados aprimorada"""
    st.header("Gerenciamento de Dados")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Importar Dados")
        uploaded_files = st.file_uploader(
            "Carregar arquivos (CSV ou Excel)",
            type=['csv', 'xlsx'],
            help="Os arquivos devem conter colunas 'Data' e 'Unidades Vendidas'",
            accept_multiple_files=True
        )

        if uploaded_files:
            if st.button("Importar Arquivos"):
                with st.spinner("Processando arquivos..."):
                    if system.import_data(uploaded_files):
                        st.rerun()

    with col2:
        st.subheader("Inserir Dados Manualmente")
        with st.form("manual_data_form"):
            col1, col2 = st.columns(2)

            with col1:
                date = st.date_input("Data", value=datetime.now())
                units = st.number_input("Unidades Vendidas", min_value=0, step=1)

            with col2:
                products = system.get_product_list()
                new_product = st.text_input("Novo Produto (ou selecione abaixo)")

                if products:
                    selected_product = st.selectbox(
                        "Produto Existente",
                        options=products,
                        index=0
                    )
                    product = new_product if new_product else selected_product
                else:
                    product = new_product if new_product else "Padaria Geral"

                categories = system.get_category_list()
                new_category = st.text_input("Nova Categoria (ou selecione abaixo)")

                if categories:
                    selected_category = st.selectbox(
                        "Categoria Existente",
                        options=categories,
                        index=0
                    )
                    category = new_category if new_category else selected_category
                else:
                    category = new_category if new_category else "Geral"

            if st.form_submit_button("Adicionar Dados"):
                if system.add_manual_data(date, units, product, category):
                    st.rerun()

    st.divider()
    st.subheader("Visualiza√ß√£o dos Dados")

    if not system.data.empty:
        # Filtros avan√ßados
        with st.expander("Filtros Avan√ßados"):
            col1, col2 = st.columns(2)

            with col1:
                start_date = st.date_input(
                    "Data Inicial",
                    value=system.data['Data'].min(),
                    min_value=system.data['Data'].min(),
                    max_value=system.data['Data'].max()
                )

            with col2:
                end_date = st.date_input(
                    "Data Final",
                    value=system.data['Data'].max(),
                    min_value=system.data['Data'].min(),
                    max_value=system.data['Data'].max()
                )

            products = system.get_product_list()
            if products:
                selected_products = st.multiselect(
                    "Produtos",
                    options=products,
                    default=products
                )
            else:
                selected_products = []

            categories = system.get_category_list()
            if categories:
                selected_categories = st.multiselect(
                    "Categorias",
                    options=categories,
                    default=categories
                )
            else:
                selected_categories = []

        # Aplicar filtros
        filtered_data = system.data[
            (system.data['Data'] >= pd.to_datetime(start_date)) &
            (system.data['Data'] <= pd.to_datetime(end_date))
            ]

        if selected_products:
            filtered_data = filtered_data[filtered_data['Produto'].isin(selected_products)]
        if selected_categories:
            filtered_data = filtered_data[filtered_data['Categoria'].isin(selected_categories)]

        # Mostrar dados
        st.dataframe(filtered_data, use_container_width=True, hide_index=True)

        # Mostrar estat√≠sticas b√°sicas
        stats = system.calculate_statistics(filtered_data)

        st.write(f"**Total de registros:** {stats['total']}")
        st.write(f"**Per√≠odo:** {stats['start_date'].date()} a {stats['end_date'].date()}")
        st.write(f"**M√©dia di√°ria:** {stats['mean']:.2f} unidades")
        st.write(f"**Mediana di√°ria:** {stats['median']:.2f} unidades")

        if 'products' in stats:
            st.write(f"**N√∫mero de produtos:** {stats['products']}")
        if 'categories' in stats:
            st.write(f"**N√∫mero de categorias:** {stats['categories']}")

        if len(filtered_data) < 30:
            st.warning("S√£o necess√°rios pelo menos 30 dias de dados para previs√µes confi√°veis.")

        if st.button("Limpar Todos os Dados", type="primary"):
            system.clear_data()
            st.rerun()
    else:
        st.info("Nenhum dado carregado. Importe arquivos ou insira dados manualmente.")


def show_forecast_tab(system: AdvancedDemandForecastSystem) -> None:
    """Exibe a aba de previs√£o de demanda aprimorada"""
    st.header("Previs√£o de Demanda")

    if system.data.empty:
        st.warning("Carregue dados na aba 'üìä Dados' antes de executar previs√µes.")
        return

    if len(system.data) < 30:
        st.warning("Aten√ß√£o: S√£o recomendados pelo menos 30 dias de dados para previs√µes confi√°veis.")

    col1, col2 = st.columns(2)

    with col1:
        model = st.selectbox(
            "Selecione o Modelo",
            ["ARIMA", "SARIMA", "Holt-Winters", "Prophet", "Random Forest", "XGBoost"],
            help="ARIMA: Modelo estat√≠stico para s√©ries temporais\nSARIMA: ARIMA com sazonalidade\nHolt-Winters: Modelo com componentes de tend√™ncia e sazonalidade\nProphet: Modelo do Facebook para s√©ries temporais\nRandom Forest/XGBoost: Modelos de machine learning"
        )

    with col2:
        horizon = st.selectbox(
            "Horizonte de Previs√£o (dias)",
            [7, 14, 30],
            help="N√∫mero de dias no futuro para prever"
        )

    # Sele√ß√£o de produto e categoria se houver m√∫ltiplos
    products = system.get_product_list()
    categories = system.get_category_list()

    if products or categories:
        cols = st.columns(2)

        with cols[0]:
            if products:
                product = st.selectbox(
                    "Produto para Previs√£o",
                    options=["Todos"] + products,
                    index=0
                )
                product = None if product == "Todos" else product
            else:
                product = None

        with cols[1]:
            if categories:
                category = st.selectbox(
                    "Categoria para Previs√£o",
                    options=["Todos"] + categories,
                    index=0
                )
                category = None if category == "Todos" else category
            else:
                category = None
    else:
        product = None
        category = None

    # Configura√ß√µes espec√≠ficas do modelo
    if model in ["ARIMA", "SARIMA", "Holt-Winters", "Random Forest", "XGBoost", "Prophet"]:
        with st.expander(f"Configura√ß√µes {model}"):
            if model == "ARIMA":
                st.write("Par√¢metros ARIMA (p, d, q)")
                col1, col2, col3 = st.columns(3)

                with col1:
                    p = st.number_input("Ordem AR (p)", min_value=0, max_value=10,
                                        value=st.session_state.model_params['ARIMA']['order'][0])
                with col2:
                    d = st.number_input("Ordem de Diferencia√ß√£o (d)", min_value=0, max_value=2,
                                        value=st.session_state.model_params['ARIMA']['order'][1])
                with col3:
                    q = st.number_input("Ordem MA (q)", min_value=0, max_value=10,
                                        value=st.session_state.model_params['ARIMA']['order'][2])

                st.session_state.model_params['ARIMA']['order'] = (p, d, q)

                if st.button("Otimizar Par√¢metros ARIMA"):
                    with st.spinner("Procurando melhores par√¢metros..."):
                        system.auto_tune_model("ARIMA")

            elif model == "SARIMA":
                st.write("Par√¢metros SARIMA")
                cols = st.columns(4)

                with cols[0]:
                    p = st.number_input("Ordem AR (p)", min_value=0, max_value=3,
                                        value=st.session_state.model_params['SARIMA']['order'][0])
                with cols[1]:
                    d = st.number_input("Ordem Diferencia√ß√£o (d)", min_value=0, max_value=2,
                                        value=st.session_state.model_params['SARIMA']['order'][1])
                with cols[2]:
                    q = st.number_input("Ordem MA (q)", min_value=0, max_value=3,
                                        value=st.session_state.model_params['SARIMA']['order'][2])

                st.write("Par√¢metros Sazonais (P, D, Q, m)")
                cols = st.columns(4)

                with cols[0]:
                    P = st.number_input("Ordem Sazonal AR (P)", min_value=0, max_value=3,
                                        value=st.session_state.model_params['SARIMA']['seasonal_order'][0])
                with cols[1]:
                    D = st.number_input("Ordem Sazonal Dif (D)", min_value=0, max_value=2,
                                        value=st.session_state.model_params['SARIMA']['seasonal_order'][1])
                with cols[2]:
                    Q = st.number_input("Ordem Sazonal MA (Q)", min_value=0, max_value=3,
                                        value=st.session_state.model_params['SARIMA']['seasonal_order'][2])
                with cols[3]:
                    m = st.number_input("Per√≠odo Sazonal (m)", min_value=2, value=7)

                st.session_state.model_params['SARIMA']['order'] = (p, d, q)
                st.session_state.model_params['SARIMA']['seasonal_order'] = (P, D, Q, m)

                if st.button("Otimizar Par√¢metros SARIMA"):
                    with st.spinner("Procurando melhores par√¢metros..."):
                        system.auto_tune_model("SARIMA")

            elif model == "Holt-Winters":
                col1, col2 = st.columns(2)

                with col1:
                    trend = st.selectbox(
                        "Tend√™ncia",
                        ['add', 'mul'],
                        index=0 if st.session_state.model_params['Holt-Winters']['trend'] == 'add' else 1,
                        help="Tipo de componente de tend√™ncia"
                    )
                    seasonal = st.selectbox(
                        "Sazonalidade",
                        ['add', 'mul'],
                        index=0 if st.session_state.model_params['Holt-Winters']['seasonal'] == 'add' else 1,
                        help="Tipo de componente sazonal"
                    )

                with col2:
                    seasonal_periods = st.number_input(
                        "Per√≠odo Sazonal",
                        min_value=2,
                        value=st.session_state.model_params['Holt-Winters']['seasonal_periods'],
                        help="N√∫mero de per√≠odos em um ciclo sazonal (ex: 7 para semana)"
                    )

                st.session_state.model_params['Holt-Winters'] = {
                    'trend': trend,
                    'seasonal': seasonal,
                    'seasonal_periods': seasonal_periods
                }

            elif model == "Prophet":
                changepoint_prior_scale = st.slider(
                    "Flexibilidade da Tend√™ncia",
                    min_value=0.01,
                    max_value=0.5,
                    value=st.session_state.model_params['Prophet']['changepoint_prior_scale'],
                    step=0.01,
                    help="Controla qu√£o flex√≠vel √© a tend√™ncia"
                )

                seasonality_prior_scale = st.slider(
                    "For√ßa da Sazonalidade",
                    min_value=1.0,
                    max_value=20.0,
                    value=st.session_state.model_params['Prophet']['seasonality_prior_scale'],
                    step=1.0,
                    help="Controla a for√ßa dos componentes sazonais"
                )

                st.session_state.model_params['Prophet'] = {
                    'changepoint_prior_scale': changepoint_prior_scale,
                    'seasonality_prior_scale': seasonality_prior_scale
                }

            elif model == "Random Forest":
                col1, col2 = st.columns(2)

                with col1:
                    n_estimators = st.number_input(
                        "N√∫mero de √Årvores",
                        min_value=10,
                        max_value=500,
                        value=st.session_state.model_params['Random Forest']['n_estimators']
                    )

                with col2:
                    max_depth = st.number_input(
                        "Profundidade M√°xima",
                        min_value=1,
                        max_value=20,
                        value=st.session_state.model_params['Random Forest'].get('max_depth', 5),
                        help="None para profundidade ilimitada"
                    )

                st.session_state.model_params['Random Forest'] = {
                    'n_estimators': n_estimators,
                    'max_depth': max_depth if max_depth > 0 else None
                }

                if st.button("Otimizar Random Forest"):
                    with st.spinner("Procurando melhores par√¢metros..."):
                        system.auto_tune_model("Random Forest")

            elif model == "XGBoost":
                col1, col2 = st.columns(2)

                with col1:
                    n_estimators = st.number_input(
                        "N√∫mero de √Årvores",
                        min_value=10,
                        max_value=500,
                        value=st.session_state.model_params['XGBoost']['n_estimators']
                    )

                with col2:
                    max_depth = st.number_input(
                        "Profundidade M√°xima",
                        min_value=1,
                        max_value=10,
                        value=st.session_state.model_params['XGBoost']['max_depth']
                    )

                learning_rate = st.slider(
                    "Taxa de Aprendizado",
                    min_value=0.01,
                    max_value=0.3,
                    value=st.session_state.model_params['XGBoost']['learning_rate'],
                    step=0.01
                )

                st.session_state.model_params['XGBoost'] = {
                    'n_estimators': n_estimators,
                    'max_depth': max_depth,
                    'learning_rate': learning_rate
                }

                if st.button("Otimizar XGBoost"):
                    with st.spinner("Procurando melhores par√¢metros..."):
                        system.auto_tune_model("XGBoost")

    if st.button("Executar Previs√£o", type="primary"):
        with st.spinner(f"Executando previs√£o com {model}..."):
            if system.run_forecast(model, horizon, product, category):
                st.rerun()

    if system.forecast_results:
        st.divider()
        st.subheader("Resultados da Previs√£o")

        # Mostrar m√©tricas de erro se existirem
        if system.forecast_results.get('error_metrics'):
            st.write("**M√©tricas de Avalia√ß√£o da Previs√£o**")

            cols = st.columns(3)
            cols[0].metric("MAPE (Erro %)", f"{system.forecast_results['error_metrics']['MAPE']:.2f}%")
            cols[1].metric("RMSE", f"{system.forecast_results['error_metrics']['RMSE']:.2f}")
            cols[2].metric("Taxa de Acerto", f"{system.forecast_results['error_metrics']['Accuracy']:.2f}%")

        # Dados para o gr√°fico
        filter_condition = True
        if product and 'Produto' in system.data.columns:
            filter_condition &= (system.data['Produto'] == product)
        if category and 'Categoria' in system.data.columns:
            filter_condition &= (system.data['Categoria'] == category)

        historical_data = system.data[filter_condition]
        forecast_df = system.forecast_results['forecast']

        # Criar gr√°fico interativo com Plotly
        fig = go.Figure()

        # Adicionar hist√≥rico
        fig.add_trace(go.Scatter(
            x=historical_data['Data'],
            y=historical_data['Unidades Vendidas'],
            mode='lines',
            name='Hist√≥rico',
            line=dict(color='blue')
        ))

        # Adicionar previs√£o
        fig.add_trace(go.Scatter(
            x=forecast_df['Data'],
            y=forecast_df['Unidades Previstas'],
            mode='lines',
            name=f'Previs√£o ({system.forecast_results["model"]})',
            line=dict(color='red', dash='dash')
        ))

        # Adicionar intervalo de confian√ßa se dispon√≠vel
        if 'Previs√£o M√≠nima' in forecast_df.columns and 'Previs√£o M√°xima' in forecast_df.columns:
            fig.add_trace(go.Scatter(
                x=pd.concat([forecast_df['Data'], forecast_df['Data'][::-1]]),
                y=pd.concat([forecast_df['Previs√£o M√°xima'], forecast_df['Previs√£o M√≠nima'][::-1]]),
                fill='toself',
                fillcolor='rgba(255,0,0,0.2)',
                line_color='rgba(255,255,255,0)',
                name='Intervalo de Confian√ßa',
                showlegend=True
            ))

        # Configurar layout
        title = f"Previs√£o de Demanda - {system.forecast_results['model']}"
        if product:
            title += f" - {product}"
        if category:
            title += f" ({category})"

        fig.update_layout(
            title=title,
            xaxis_title="Data",
            yaxis_title="Unidades Vendidas",
            hovermode="x unified",
            showlegend=True,
            template="plotly_white"
        )

        st.plotly_chart(fig, use_container_width=True)

        # Tabela de previs√µes
        st.subheader("Detalhes da Previs√£o")

        display_df = forecast_df.copy()
        display_df['Dia da Semana'] = display_df['Data'].dt.day_name()

        st.dataframe(
            display_df.style.format({
                'Unidades Previstas': '{:.2f}',
                'Previs√£o M√≠nima': '{:.2f}',
                'Previs√£o M√°xima': '{:.2f}'
            }),
            column_order=['Data', 'Dia da Semana', 'Unidades Previstas', 'Previs√£o M√≠nima', 'Previs√£o M√°xima'],
            use_container_width=True,
            hide_index=True
        )


def show_visualization_tab(system: AdvancedDemandForecastSystem) -> None:
    """Exibe a aba de visualiza√ß√£o de dados aprimorada"""
    st.header("Visualiza√ß√£o de Dados")

    if system.data.empty:
        st.warning("Nenhum dado dispon√≠vel para visualiza√ß√£o")
        return

    # Filtros avan√ßados
    with st.expander("Filtros"):
        col1, col2 = st.columns(2)

        with col1:
            start_date = st.date_input(
                "Data Inicial",
                min_value=system.data['Data'].min(),
                max_value=system.data['Data'].max(),
                value=system.data['Data'].min()
            )

        with col2:
            end_date = st.date_input(
                "Data Final",
                min_value=system.data['Data'].min(),
                max_value=system.data['Data'].max(),
                value=system.data['Data'].max()
            )

        products = system.get_product_list()
        if products:
            selected_products = st.multiselect(
                "Produtos",
                options=products,
                default=products[:min(3, len(products))] if products else []
            )
        else:
            selected_products = []

        categories = system.get_category_list()
        if categories:
            selected_categories = st.multiselect(
                "Categorias",
                options=categories,
                default=categories[:min(3, len(categories))] if categories else []
            )
        else:
            selected_categories = []

    # Filtrar dados
    filtered_data = system.data[
        (system.data['Data'] >= pd.to_datetime(start_date)) &
        (system.data['Data'] <= pd.to_datetime(end_date))
        ]

    if selected_products:
        filtered_data = filtered_data[filtered_data['Produto'].isin(selected_products)]
    if selected_categories:
        filtered_data = filtered_data[filtered_data['Categoria'].isin(selected_categories)]

    if filtered_data.empty:
        st.warning("Nenhum dado no per√≠odo selecionado")
        return

    # Gr√°ficos interativos
    tab1, tab2, tab3, tab4 = st.tabs(["S√©rie Temporal", "An√°lise Sazonal", "Compara√ß√£o de Produtos", "Distribui√ß√£o"])

    with tab1:
        group_col = None
        if selected_products and len(selected_products) > 1:
            group_col = 'Produto'
        elif selected_categories and len(selected_categories) > 1:
            group_col = 'Categoria'

        if group_col:
            fig = px.line(
                filtered_data,
                x='Data',
                y='Unidades Vendidas',
                color=group_col,
                title=f"Vendas por Data e {group_col}",
                labels={'Unidades Vendidas': 'Unidades Vendidas', 'Data': 'Data'}
            )
        else:
            fig = px.line(
                filtered_data,
                x='Data',
                y='Unidades Vendidas',
                title="Vendas por Data",
                labels={'Unidades Vendidas': 'Unidades Vendidas', 'Data': 'Data'}
            )

        fig.update_layout(
            hovermode="x unified",
            showlegend=True if group_col else False,
            template="plotly_white"
        )
        st.plotly_chart(fig, use_container_width=True)

    with tab2:
        filtered_data['DiaSemana'] = filtered_data['Data'].dt.day_name()
        filtered_data['Mes'] = filtered_data['Data'].dt.month_name()

        group_col = None
        if selected_products and len(selected_products) > 1:
            group_col = 'Produto'
        elif selected_categories and len(selected_categories) > 1:
            group_col = 'Categoria'

        if group_col:
            fig = px.box(
                filtered_data,
                x='DiaSemana',
                y='Unidades Vendidas',
                color=group_col,
                title=f"Distribui√ß√£o por Dia da Semana por {group_col}",
                labels={'Unidades Vendidas': 'Unidades Vendidas', 'DiaSemana': 'Dia da Semana'}
            )
        else:
            fig = px.box(
                filtered_data,
                x='DiaSemana',
                y='Unidades Vendidas',
                title="Distribui√ß√£o por Dia da Semana",
                labels={'Unidades Vendidas': 'Unidades Vendidas', 'DiaSemana': 'Dia da Semana'}
            )

        fig.update_layout(
            xaxis={'categoryorder': 'array',
                   'categoryarray': ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']},
            template="plotly_white"
        )
        st.plotly_chart(fig, use_container_width=True)

    with tab3:
        if (not selected_products or len(selected_products) < 2) and (
                not selected_categories or len(selected_categories) < 2):
            st.info("Selecione pelo menos 2 produtos ou categorias para compara√ß√£o")
        else:
            # Agrupar por produto/categoria e data
            group_col = None
            if selected_products and len(selected_products) > 1:
                group_col = 'Produto'
            elif selected_categories and len(selected_categories) > 1:
                group_col = 'Categoria'

            comparison_data = filtered_data.groupby([group_col, pd.Grouper(key='Data', freq='W')])[
                'Unidades Vendidas'].sum().reset_index()

            fig = px.line(
                comparison_data,
                x='Data',
                y='Unidades Vendidas',
                color=group_col,
                title=f"Compara√ß√£o Semanal de Vendas por {group_col}",
                labels={'Unidades Vendidas': 'Unidades Vendidas', 'Data': 'Data'}
            )

            fig.update_layout(
                hovermode="x unified",
                template="plotly_white"
            )
            st.plotly_chart(fig, use_container_width=True)

    with tab4:
        st.subheader("Distribui√ß√£o das Vendas")

        group_col = None
        if selected_products and len(selected_products) > 1:
            group_col = 'Produto'
        elif selected_categories and len(selected_categories) > 1:
            group_col = 'Categoria'

        if group_col:
            fig = px.histogram(
                filtered_data,
                x='Unidades Vendidas',
                color=group_col,
                marginal="box",
                title=f"Distribui√ß√£o de Vendas por {group_col}",
                barmode="overlay"
            )
        else:
            fig = px.histogram(
                filtered_data,
                x='Unidades Vendidas',
                marginal="box",
                title="Distribui√ß√£o de Vendas"
            )

        st.plotly_chart(fig, use_container_width=True)


def show_stats_tab(system: AdvancedDemandForecastSystem) -> None:
    """Exibe a aba de estat√≠sticas aprimorada"""
    st.header("Estat√≠sticas da Previs√£o")

    if not system.forecast_results:
        st.warning("Execute uma previs√£o na aba 'üîÆ Previs√£o' para ver estat√≠sticas")
        return

    forecast_df = system.forecast_results['forecast']
    forecast_data = forecast_df['Unidades Previstas']

    # M√©tricas principais
    col1, col2, col3, col4 = st.columns(4)

    col1.metric("M√©dia Di√°ria", f"{forecast_data.mean():.1f} unidades")
    col2.metric("M√≠nimo Di√°rio", f"{forecast_data.min():.1f} unidades")
    col3.metric("M√°ximo Di√°rio", f"{forecast_data.max():.1f} unidades")
    col4.metric("Total Previsto", f"{forecast_data.sum():.1f} unidades")

    # Mostrar m√©tricas de erro se existirem
    if system.forecast_results.get('error_metrics'):
        st.divider()
        st.subheader("M√©tricas de Qualidade da Previs√£o")

        cols = st.columns(3)
        cols[0].metric("MAPE (Erro %)", f"{system.forecast_results['error_metrics']['MAPE']:.2f}%")
        cols[1].metric("RMSE", f"{system.forecast_results['error_metrics']['RMSE']:.2f}")
        cols[2].metric("Taxa de Acerto", f"{system.forecast_results['error_metrics']['Accuracy']:.2f}%")

    st.divider()

    # An√°lise por dia da semana
    forecast_df['Dia da Semana'] = forecast_df['Data'].dt.day_name()

    # Agrupar por dia da semana
    weekday_stats = forecast_df.groupby('Dia da Semana')['Unidades Previstas'].agg(['mean', 'sum'])
    weekday_stats = weekday_stats.reindex(
        ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])

    st.subheader("M√©dia por Dia da Semana")
    fig = px.bar(
        weekday_stats,
        x=weekday_stats.index,
        y='mean',
        labels={'mean': 'M√©dia de Unidades', 'Dia da Semana': 'Dia da Semana'},
        color_discrete_sequence=['#636EFA']
    )
    fig.update_layout(
        xaxis_title="Dia da Semana",
        yaxis_title="M√©dia de Unidades Previstas",
        template="plotly_white"
    )
    st.plotly_chart(fig, use_container_width=True)

    # Tabela detalhada
    st.subheader("Detalhes da Previs√£o")
    st.dataframe(
        forecast_df.style.format({
            'Unidades Previstas': '{:.1f}',
            'Previs√£o M√≠nima': '{:.1f}',
            'Previs√£o M√°xima': '{:.1f}'
        }),
        column_order=['Data', 'Dia da Semana', 'Unidades Previstas', 'Previs√£o M√≠nima', 'Previs√£o M√°xima'],
        use_container_width=True,
        hide_index=True
    )


def show_export_tab(system: AdvancedDemandForecastSystem) -> None:
    """Exibe a aba de exporta√ß√£o de dados aprimorada"""
    st.header("Exportar Dados e Relat√≥rios")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Exportar para Excel")
        if st.button("Gerar Arquivo Excel"):
            excel_file = system.export_to_excel()
            if excel_file:
                st.download_button(
                    label="Baixar Excel",
                    data=excel_file,
                    file_name="previsao_demanda.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

    with col2:
        st.subheader("Exportar para PDF")
        if st.button("Gerar Relat√≥rio PDF"):
            pdf_file = system.export_to_pdf()
            if pdf_file:
                st.download_button(
                    label="Baixar PDF",
                    data=pdf_file,
                    file_name="relatorio_previsao.pdf",
                    mime="application/pdf"
                )

    st.divider()

    # Backup e restaura√ß√£o
    st.subheader("Backup de Dados")

    if st.session_state.data_backups:
        backup_dates = [f"Backup {i + 1} ({len(backup['data'])} registros, {len(backup['forecast_history'])} previs√µes)"
                        for i, backup in enumerate(st.session_state.data_backups)]

        selected_backup = st.selectbox(
            "Selecione um backup para restaurar",
            options=backup_dates
        )

        if st.button("Restaurar Backup"):
            index = backup_dates.index(selected_backup)
            system.data = st.session_state.data_backups[index]['data'].copy()
            system.forecast_results = st.session_state.data_backups[index]['forecast_results'].copy() if \
            st.session_state.data_backups[index]['forecast_results'] else None
            system.forecast_history = st.session_state.data_backups[index]['forecast_history'].copy()
            system.save_data()
            st.success("Backup restaurado com sucesso!")
            st.rerun()
    else:
        st.info("Nenhum backup dispon√≠vel")


def show_settings_tab(system: AdvancedDemandForecastSystem) -> None:
    """Exibe a aba de configura√ß√µes aprimorada"""
    st.header("Configura√ß√µes do Sistema")

    st.subheader("Configura√ß√µes de Modelos")

    with st.expander("Configura√ß√µes ARIMA"):
        st.write("Par√¢metros atuais:", st.session_state.model_params['ARIMA'])
        if st.button("Redefinir ARIMA para padr√µes"):
            st.session_state.model_params['ARIMA'] = {'order': (5, 1, 0)}
            st.success("Par√¢metros ARIMA redefinidos")

    with st.expander("Configura√ß√µes SARIMA"):
        st.write("Par√¢metros atuais:", st.session_state.model_params['SARIMA'])
        if st.button("Redefinir SARIMA para padr√µes"):
            st.session_state.model_params['SARIMA'] = {
                'order': (1, 1, 1),
                'seasonal_order': (1, 1, 1, 7)
            }
            st.success("Par√¢metros SARIMA redefinidos")

    with st.expander("Configura√ß√µes Holt-Winters"):
        st.write("Par√¢metros atuais:", st.session_state.model_params['Holt-Winters'])
        if st.button("Redefinir Holt-Winters para padr√µes"):
            st.session_state.model_params['Holt-Winters'] = {
                'trend': 'add',
                'seasonal': 'add',
                'seasonal_periods': 7
            }
            st.success("Par√¢metros Holt-Winters redefinidos")

    with st.expander("Configura√ß√µes Random Forest"):
        st.write("Par√¢metros atuais:", st.session_state.model_params['Random Forest'])
        if st.button("Redefinir Random Forest para padr√µes"):
            st.session_state.model_params['Random Forest'] = {
                'n_estimators': 100,
                'max_depth': None
            }
            st.success("Par√¢metros Random Forest redefinidos")

    with st.expander("Configura√ß√µes XGBoost"):
        st.write("Par√¢metros atuais:", st.session_state.model_params['XGBoost'])
        if st.button("Redefinir XGBoost para padr√µes"):
            st.session_state.model_params['XGBoost'] = {
                'n_estimators': 100,
                'max_depth': 3,
                'learning_rate': 0.1
            }
            st.success("Par√¢metros XGBoost redefinidos")

    with st.expander("Configura√ß√µes Prophet"):
        st.write("Par√¢metros atuais:", st.session_state.model_params['Prophet'])
        if st.button("Redefinir Prophet para padr√µes"):
            st.session_state.model_params['Prophet'] = {
                'changepoint_prior_scale': 0.05,
                'seasonality_prior_scale': 10
            }
            st.success("Par√¢metros Prophet redefinidos")

    st.subheader("Sobre o Sistema")
    st.write("""
        **Sistema Avan√ßado de Previs√£o de Demanda - Padaria Master**  
        Vers√£o 4.0  
        Desenvolvido para gest√£o profissional de demanda  

        **Recursos principais:**  
        - M√∫ltiplos modelos de previs√£o (ARIMA, SARIMA, Holt-Winters, Prophet, Random Forest, XGBoost)  
        - Suporte a m√∫ltiplos produtos e categorias  
        - Intervalos de confian√ßa nas previs√µes  
        - M√©tricas de qualidade da previs√£o (MAPE, RMSE, Taxa de Acerto)  
        - Gr√°ficos interativos  
        - Otimiza√ß√£o autom√°tica de par√¢metros  
        - Exporta√ß√£o para Excel e PDF  

        ¬© 2023 - Todos os direitos reservados
    """)


if __name__ == "__main__":
    main()